[
 {
  "url": "https://www.aaai.org/Papers/AAAI/1992/AAAI92-119.pdf",
  "title": "An Empirical Analysis of Terminological Representation Systems",
  "year": 1992,
  "venue": "AAAI",
  "abstract": "The family of terminological representation systems has its roots in the representation system KLONE. Since the development of this system more than a dozen similar representation systems have been developed by various research groups. These systems vary along a number of dimensions. In this paper, we present the results of an empirical analysis of six such systems. Surprisingly, the systems turned out to be quite diverse leading to problems when transporting knowledge bases from one system to another. Additionally, the runtime performance between different systems and knowledge bases varied more than we expected. Finally, our empirical runtime performance results give an idea of what runtime performance to expect from such representation systems. These findings complement previously reported analytical results about the computational complexity of reasoning in such systems.",
  "stance": 0.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1994/AAAI94-014.pdf",
  "title": "Experimentally Evaluating Communicative Strategies: The Effect of the Task",
  "year": 1994,
  "venue": "AAAI",
  "abstract": "Effective problem solving among multiple agents requires a better understanding of the role of communication in collaboration. In this paper we show that there are communicative strategies that greatly improve the performance of resource-bounded agents, but that these strategies are highly sensitive to the task requirements, situation parameters and agents’ resource limitations. We base our argument on two sources of evidence: (1) an analysis of a corpus of 55 problem solving dialogues, and (2) experimental simulations of collaborative problem solving dialogues in an experimental world, Design-World, where we parameterize task requirements, agents’ resources and communicative strategies.",
  "stance": 0.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1994/AAAI94-129.pdf",
  "title": "Unclear Distinctions Lead to Unnecessary Shortcomings: Examining the Rule Versus Fact, Role versus Filler, and Type Versus Predicate Distinctions from a Connectionist Representation and Reasoning Perspective",
  "year": 1994,
  "venue": "AAAI",
  "abstract": "This paper deals with three distinctions pertaining to knowledge representation, namely, the rules vs facts distinction, roles vs fillers distinction, and predicates vs types distinction. Though these distinctions may indeed have some intuitive appeal, the exact natures of these distinctions are not entirely clear. This paper discusses some of the problems that arise when one accords these distinctions a prominent status in a connectionist system by choosing the representational structures so as to reflect these distinctions. The example we will look at in this paper is the connectionist reasoning system developed by Ajjanagadde & Shastri(Ajjanagadde & Shastri 1991; Shastri & Ajjanagadde 1993). Their1 system performs an interesting class of inferences using activation synchrony to represent dynamic bindings. The rule/fact, role/filler, type/predicate distinctions figure predominantly in the way knowledge is encoded in their system. We will discuss some significant shortcomings this leads to. Then, we will propose a much more uniform scheme for representing knowledge. The resulting system enjoys some significant advantages over Ajjanagadde & Shastri’s system, while retaining the idea of using synchrony to represent bindings.",
  "stance": 0.5
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1994/AAAI94-139.pdf",
  "title": "On the Relation between the Coherence and Foundations Theories of Belief Revision",
  "year": 1994,
  "venue": "AAAI",
  "abstract": "Two recent, papers, (Ggrdenfors 1990; Doyle 1992), try to assess the relative merits of the two main approaches to belief revision, the foundations and coherence theories, but leave open the question of the mathematical connections between them. We answer this question by showing that the foundations and coherence theories of belief revision are mathematically equivalent. The result also has consequences for nonmonotonic reasoning, as it, entails that Poole’s system of default, reasoning and Shoham’s preferential logic are expressively equivalent, in that they can represent the same set of non monotonic consequence relations.",
  "stance": 0.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1994/AAAI94-160.pdf",
  "title": "The First Law of Robotics (A Call to Arms)",
  "year": 1994,
  "venue": "AAAI",
  "abstract": "Even before the advent of Artificial Intelligence, science fiction writer Isaac Asimov recognized that an agent must place the protection of humans from harm at a higher priority than obeying human orders. Inspired by Asimov, we pose the following fundamental questions: (1) How should one formalize the rich, but informal, notion of “harm”? (2) How can an agent avoid performing harmful actions, and do so in a computationally tractable manner? (3) How should an agent resolve conflict between its goals and the need to avoid harm? (4) When should an agent prevent a human from harming herself? While we address some of these questions in technical detail, the primary goal of this paper is to focus attention on Asimov’s concern: society will reject autonomous agents unless we have some credible means of making them safe! The Three Laws of Robotics: A robot may not injure a human being, or, through inaction, allow a human being to come to harm. A robot must obey orders given it by human beings except where such orders would conflict with the First Law. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law. Isaac Asimov (Asimov 1942).",
  "stance": 0.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1994/AAAI94-162.pdf",
  "title": "On the Nature of Modal Truth Criteria in Planning",
  "year": 1994,
  "venue": "AAAI",
  "abstract": "Chapman’s paper, “Planning for Conjunctive Goals,” has been widely acknowledged for its contribution toward understanding the nature of nonlinear (partial-order) planning, and it has been one of the bases of later work by others---but it is not free of problems. This paper addresses some problems involving modal truth and the Modal Truth Criterion (MTC). Our results are as follows: Even though modal duality is a fundamental axiom of classical modal logics, it does not hold for modal truth in Chapman’s plans; i.e., “necessarily p” is not equivalent to “not possibly lp.” Although the MTC for necessary truth is correct, the MTC for possible truth is incorrect: it provides necessary but insz#kient conditions for ensuring possible truth. Furthermore, even though necessary truth can be determined in polynomial time, possible truth is NP-hard. If we rewrite the MTC to talk about modal conditional truth (i.e., modal truth conditional on executability) rather than modal truth, then both the MTC for necessary conditional truth and the MTC for possible conditional truth are correct; and both can be computed in polynomial time.",
  "stance": -0.8
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1994/AAAI94-270.pdf",
  "title": "Model-Based Sensor Diagnosis: When Monitoring Should be Monitored",
  "year": 1994,
  "venue": "AAAI",
  "abstract": "A complex industrial plant, such as a nuclear power plant, is monitored thanks to a number of sensors. The instrumentation may be itself a complex system liable to failures. We propose a model-based sensor diagnosis system which relies on the topological description of the plant and on a set of component models. This model implicitly conceals relations involving only sensor data. Such relations must always be verified if components behave normally; thus, the detection task consists of verifying these relations. So, this work is a first step in extending the scope of model-based diagnosis, since we question here the information stemming from the plant and normally considered as safe. As further studies, we wish to monitor this detection system itself; i.e., whenever the instrumentation is supposed to behave correctly, nonverified constraints point out to errors in the plant model.",
  "stance": 0.2
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1996/AAAI96-013.pdf",
  "title": "Nearly Monotonic Problems: A Key to Effective FA/C Distributed Sensor Interpretation?",
  "year": 1996,
  "venue": "AAAI",
  "abstract": "The functionally-accurate, cooperative (FA/C) distributed problem-solving paradigm is one approach for organizing distributed problem solving among homogeneous, cooperating agents. A key assumption of the FA/C model has been that the agents’ local solutions can substitute for the raw data in determining the global solutions. This is not the case in general, however. Does this mean that researchers’ intuitions have been wrong and/or that FA/C problem solving is not likely to be effective ? We suggest that some domains have a characteristic that can account for the success of exchanging mainly local solutions. We call such problems nearly monotonic. This concept is discussed in the context of FA/C-based distributed sensor interpretation.",
  "stance": 0.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1996/AAAI96-097.pdf",
  "title": "Formalizing Narratives Using Nested Circumscription",
  "year": 1996,
  "venue": "AAAI",
  "abstract": "The representation of narratives of actions and observations is a current issue in Knowledge Representation, where traditional plan-oriented treatments of action seem to fall short. To address narratives, Pinto and Reiter have extended Situation Calculus axioms, Kowalski and Sergot have introduced the Event Calculus in Logic Programming, and Baral et al. have defined the specification language C which allows to express actual and hypothetical situations in a uniform setting. The L entailment relation can formalize several forms of reasoning about actions and change. In this paper we illustrate a translation of L theories into Nested Abnormality Theories, a novel form of circumscription. The proof of soundness and completeness of the translation is the main technical result of the paper, but attention is also devoted to the features of Nested Abnormality Theories to capture commonsense reasoning in general and to clarify which assumptions a logical formalization forces upon a domain. These results also help clarifying the relationship between L and other recent circumscriptive formalizations for narratives, such as Miller and Shanahan’s. Content Areas Temporal Reasoning, Nonmonotonic Reasoning, Knowledge Representation.",
  "stance": 0.5
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1996/AAAI96-099.pdf",
  "title": "On the Range of Applicability of Baker’s Approach to the Frame Problem",
  "year": 1996,
  "venue": "AAAI",
  "abstract": "We investigate the range of applicability of Baker’s approach to the frame problem using an action language. We show that for temporal projection and deterministic domains, Baker’s approach gives the intuitively expected results.",
  "stance": 0.2
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1996/AAAI96-118.pdf",
  "title": "Testing the Robustness of the Genetic Algorithm on the Floating Building Block Representation",
  "year": 1996,
  "venue": "AAAI",
  "abstract": "Recent studies on a floating building block representation for the genetic algorithm (GA) suggest that there are many advantages to using the floating representation. This paper investigates the behavior of the GA on floating representation problems in response to three different types of pressures: (1) a reduction in the amount of genetic material available to the GA during the problem solving process, (2) functions which have negative-valued building blocks, and (3) randomizing non-coding segments. Results indicate that the GA’s performance on floating representation problems is very robust. Significant reductions in genetic material (genome length) may be made with relatively small decrease in performance. The GA can effectively solve problems with negative building blocks. Randomizing non-coding segments appears to improve rather than harm GA performance.",
  "stance": 0.5
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1996/AAAI96-168.pdf",
  "title": "A Bias towards Relevance: Recognizing Plans where Goal Minimization Fails",
  "year": 1996,
  "venue": "AAAI",
  "abstract": "Domains such as multiple trauma management, in which there are multiple interacting goals that change over time, are ones in which plan recognition’s standard inductive bias towards a single explanatory goal is inappropriate. In this paper we define and argue for an alternative bias based on identifying contextually “relevant” goals. We support this claim by showing how a complementary planning system in TraumAID 2.0, a decision-support system for the management of multiple trauma, allows us to define a four-level scale of relevance and therefore, of measurable deviations from relevance. This in turn allows definition of a bias towards relevance in the incremental recognition of physician plans by TraumAID’s critiquing interface, TraumaTIQ.",
  "stance": 0.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1996/AAAI96-175.pdf",
  "title": "On the Size of Reactive Plans",
  "year": 1996,
  "venue": "AAAI",
  "abstract": "One of the most widespread approaches to reactive planning is Schoppers’ universal plans. We propose a stricter definition of universal plans which guarantees a weak notion of soundness not present in the original definition. Furthermore, we isolate three different types of completeness which capture different behaviours exhibited by universal plans. We show that universal plans which run in polynomial time and are of polynomial size cannot satisfy even the weakest type of completeness unless the polynomial hierarchy collapses. However, by relaxing either the polynomial time or the polynomial space requirement, the construction of universal plans satisfying the strongest type of completeness becomes trivial.",
  "stance": 0.5
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1996/AAAI96-194.pdf",
  "title": "A Counterexample to Theorems of Cox and Fine",
  "year": 1996,
  "venue": "AAAI",
  "abstract": "Cox’s well-known theorem justifying the use of probability is shown not to hold in finite domains. The counterexample also suggests that Cox’s assumptions are insufficient to prove the result even in infinite domains. The same counterexample is used to disprove a result of Fine on comparative conditional probability.",
  "stance": 0.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1998/AAAI98-042.pdf",
  "title": "The Branching Factor of Regular Search Spaces",
  "year": 1998,
  "venue": "AAAI",
  "abstract": "Many problems, such as the sliding-tile puzzles, generate search trees where different nodes have different numbers of children, in this case depending on the position of the blank. We show how to calculate the asymptotic branching factors of such problems, and how to efficiently compute the exact numbers of nodes at a given depth. This information is important for determining the complexity of various search algorithms on these problems. In addition to the sliding-tile puzzles, we also apply our technique to Rubik’s Cube. While our techniques are fairly straightforward, the literature is full of incorrect branching factors for these problems, and the errors in several incorrect methods are fairly subtle.",
  "stance": -1.0
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1998/AAAI98-078.pdf",
  "title": "Cooperating with People: The Intelligent Classroom",
  "year": 1998,
  "venue": "AAAI",
  "abstract": "People frequently complain that it is too difficult to figure out how to get computers to do what they want. However, with a computer system that actually tries to understand what its users are doing, people can interact in ways that are more natural to them. We have been developing a system, the Intelligent Classroom, that does exactly this. The Intelligent Classroom uses cameras and microphones to sense a speaker’s actions and then infers his intentions from those actions. Finally, it uses these intentions to decide what to do to best cooperate with the speaker. In the Intelligent Classroom, the speaker need not worry about how to operate the Classroom; he may simply go about his lecture and trust the Classroom to assist him at the appropriate moments.",
  "stance": 0.5
 },
 {
  "url": "https://www.aaai.org/Papers/AAAI/1998/AAAI98-120.pdf",
  "title": "Experimenting with Power Default Reasoning",
  "year": 1998,
  "venue": "AAAI",
  "abstract": "In this paper we explore the computational aspects of Propositional Power Default Reasoning (PDR), a form of non-monotonic reasoning which the underlying logic is Kleene’s 3-valued propositional logic. PDR leads to a concise meaning of the problem of skeptical entailment which has better complexity characteristics than the usual formalisms (co-NP(3)-Complete instead [[p-Complete). We take advantage of this in an implementation called powder to encode and solve hard graph problems and explore randomly generated instances of skeptical entailment.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/P86-1017",
  "title": "Encoding and Acquiring Meanings for Figurative Phrases",
  "year": 1986,
  "venue": "ACL",
  "abstract": "Here we address the problem of mapping phrase meanings into their conceptual representations. Figurative phrases are pervasive in human communication, yet they are difficult to explain theoretically. In fact, the ability to handle idiosyncratic behavior of phrases should be a criterion for any theory of lexical representation. Due to the huge number of such phrases in the English language, phrase representation must be amenable to parsing, generation, and also to learning. In this paper we demonstrate a semantic representation which facilitates, for a wide variety of phrases, both learning and parsing.",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/P86-1033",
  "title": "Linguistic Coherence: A Plan-Based Alternative",
  "year": 1986,
  "venue": "ACL",
  "abstract": "To fully understand a sequence of utterances, one must be able to infer implicit relationships between the utterances. Although the identification of sets of utterance relationships forms the basis for many theories of discourse, the formalization and recognition of such relationships has proven to be an extremely difficult computational task. This paper presents a plan-based approach to the representation and recognition of implicit relationships between utterances. Relationships are formulated as discourse plans, which allows their representation in terms of planning operators and their computation via a plan recognition process. By incorporating complex inferential processes relating utterances into a plan-based framework, a formalization and computability not available in the earlier works is provided.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/P87-1013",
  "title": "A Logical Version of Functional Grammar",
  "year": 1987,
  "venue": "ACL",
  "abstract": "Kay's functional-unification grammar notation [5] is a way of expressing grammars which relies on very few primitive notions. The primary syntactic structure is the feature structure, which can be visualised as a directed graph with arcs labeled by at t r ibutes of a constituent, and the primary structure-building operation is unification. In this paper we propose a mathematical formulation of FUG, using logic to give a precise account of the strings and the structures defined by any grammar written in this notation.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/P88-1017",
  "title": "Parsing Japanese Honorifics in Unification-Based Grammar",
  "year": 1988,
  "venue": "ACL",
  "abstract": "This paper presents a unification-based approach to Japanese honorifics based on a version of HPSG (Head-driven Phrase Structure Grammar)ll]121. Utterance parsing is based on lexical specifications of each lexical item, including honorifics, and a few general PSG rules using a parser capable of unifying cyclic feature structures. It is shown that the possible word orders of Japanese honori f ic predicate constituents can be automatically deduced in the proposed f ramework w i thou t independent ly specifying them. Discourse Information Change Rules (DICRs) that a l low resolving a class of anaphors in honorific contexts are also formulated.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/P89-1024",
  "title": "A Hybrid Approach to Representation in the Janus Natural Language Processor",
  "year": 1989,
  "venue": "ACL",
  "abstract": "In BBN's natural language understanding and generation system (Janus), we have used a hybrid approach to representation, employing an intensional logic for the representation of the semantics of utterances and a taxonomic language with formal semantics for specification of descriptive constants and axioms relating them. Remarkably, 99.9% of 7,000 vocabulary items in our natural language applications could be adequately axiomatlzed in the taxonomic language.",
  "stance": 0.6
 },
 {
  "url": "https://aclanthology.org/P89-1026",
  "title": "Two Constraints on Speech Act Ambiguity",
  "year": 1989,
  "venue": "ACL",
  "abstract": "Existing plan-based theories of speech act interpretation do not account for the conventional aspect of speech acts. We use patterns of linguistic features (e.g. mood, verb form, sentence adverbials, thematic roles) to suggest a range of speech act interpretations for the utterance. These are filtered using plan-bused conversational implicatures to eliminate inappropriate ones. Extended plan reasoning is available but not necessary for familiar forms. Taking speech act ambiguity seriously, with these two constraints, explains how \"Can you pass the salt?\" is a typical indirect request while \"Are you able to pass the salt?\" is not.",
  "stance": 0.6
 },
 {
  "url": "https://aclanthology.org/P89-1027",
  "title": "Treatment of Long Distance Dependencies in LFG and TAG: Functional Uncertainty in LFG Is a Corollary in TAG",
  "year": 1989,
  "venue": "ACL",
  "abstract": "In this paper the functional uncertainty machinery in LFG is compared with the treatment of long distance dependencies in TAG. It is shown that the functional uncertainty machinery is redundant in TAG, i.e.,what functional uncertainty accomplishes for LFG follows from the TAG formalism itself and some aspects of the linguistic theory instantiated in TAG. It is also shown that the analyses provided by the functional uncertainty machinery can be obtained without requiring power beyond mildly context-sensitive grammars. Some linguistic and computational aspects of these results have been briefly discussed also.",
  "stance": -0.1
 },
 {
  "url": "https://aclanthology.org/P89-1031",
  "title": "Evaluating Discourse Processing Algorithms",
  "year": 1989,
  "venue": "ACL",
  "abstract": "In order to take steps towards establishing a methodology for evaluating Natural Language systems, we conducted a case study. We attempt to evaluate two different approaches to anaphoric processing in discourse by comparing the accuracy and coverage of two published algorithms for finding the co-specifiers of pronouns in naturally occurring texts and dialogues. We present the quantitative results of handsimulating these algorithms, but this analysis naturally gives rise to both a qualitative evaluation and recommendations for performing such evaluations in general. We illustrate the general difficulties encountered with quantitative evaluation. These are problems with: (a) allowing for underlying assumptions, (b) determining how to handle underspecifications, and (c) evaluating the contribution of false positives and error chaining.",
  "stance": -0.8
 },
 {
  "url": "https://aclanthology.org/P90-1006",
  "title": "Memory Capacity and Sentence Processing",
  "year": 1990,
  "venue": "ACL",
  "abstract": "The limited capacity of working memory is intrinsic to human sentence processing, and therefore must be addressed by any theory of human sentence processing. This paper gives a theory of garden-path effects and processing overload that is based on simple assumptions about human short term memory capacity.",
  "stance": 0.2
 },
 {
  "url": "https://aclanthology.org/P91-1019",
  "title": "Subject-Dependent Co-Occurrence and Word Sense Disambiguation",
  "year": 1991,
  "venue": "ACL",
  "abstract": "We describe a method for obtaining subject-dependent word sets relative to some (subjecO domain. Using the subject classifications given in the machine-readable version of Longman's Dictionary of Contemporary English, we established subject-dependent cooccurrence links between words of the defining vocabulary to construct these \"neighborhoods\". Here, we describe the application of these neighborhoods to information retrieval, and present a method of word sense disambiguation based on these co-occurrences, an extension of previous work.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/P91-1038",
  "title": "A Preference-first Language Processor: Integrating the Unification Grammar and Markov Language Model for Speech Recognition Applications",
  "year": 1991,
  "venue": "ACL",
  "abstract": "A language processor is to find out a most promising sentence hypothesis for a given word lattice obtained from acoustic signal recognition. In this paper a new language processor is proposed, in which unification granunar and Markov language model are integrated in a word lattice parsing algorithm based on an augmented chart, and the island-driven parsing concept is combined with various preference-first parsing strategies defined by different construction principles and decision rules. Test results\"show that significant improvements in both correct rate of recognition and computation speed can be achieved .",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P92-1017",
  "title": "Inside-Outside Reestimation From Partially Bracketed Corpora",
  "year": 1992,
  "venue": "ACL",
  "abstract": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information (constituent bracketing) in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modeling of hierarchical structure than the original one. In particular, over 90% test set bracketing accuracy was achieved for grammars inferred by our algorithm from a training set of hand-parsed part-of-speech strings for sentences in the Air Travel Information System spoken language corpus. Finally, the new algorithm has better time complexity than the original one when sufficient bracketing is provided.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/P92-1023",
  "title": "GPSM: A Generalized Probabilistic Semantic Model for Ambiguity Resolution",
  "year": 1992,
  "venue": "ACL",
  "abstract": "In natural language processing, ambiguity resolution is a central issue, and can be regarded as a preference assignment problem. In this paper, a Generalized Probabilistic Semantic Model (GPSM) is proposed for preference computation. An effective semantic tagging procedure is proposed for tagging semantic features. A semantic score function is derived based on a score function, which integrates lexical, syntactic and semantic preference under a uniform formulation. The semantic score measure shows substantial improvement in structural disambiguation over a syntax-based approach.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P92-1032",
  "title": "Estimating Upper and Lower Bounds on the Performance of Word-Sense Disambiguation Programs",
  "year": 1992,
  "venue": "ACL",
  "abstract": "We have recently reported on two new word-sense disambiguation systems, one trained on bilingual material (the Canadian Hansards) and the other trained on monolingual material (Roget's Thesaurus and Grolier's Encyclopedia). After using both the monolingual and bilingual classifiers for a few months, we have convinced ourselves that the performance is remarkably good. Nevertheless, we would really like to be able to make a stronger statement, and therefore, we decided to try to develop some more objective evaluation measures. Although there has been a fair amount of literature on sense-disambiguation, the literature does not offer much guidance in how we might establish the success or failure of a proposed solution such as the two systems mentioned in the previous paragraph. Many papers avoid quantitative evaluations altogether, because it is so difficult to come up with credible estimates of performance. This paper will attempt to establish upper and lower bounds on the level of performance that can be expected in an evaluation. An estimate of the lower bound of 75% (averaged over ambiguous types) is obtained by measuring the performance produced by a baseline system that ignores context and simply assigns the most likely sense in all cases. An estimate of the upper bound is obtained by assuming that our ability to measure performance is largely limited by our ability obtain reliable judgments from human informants. Not surprisingly, the upper bound is very dependent on the instructions given to the judges. Jorgensen, for example, suspected that lexicographers tend to depend too much on judgments by a single informant and found considerable variation over judgments (only 68% agreement), as she had suspected. In our own experiments, we have set out to find word-sense disambiguation tasks where the judges can agree often enough so that we could show that they were outperforming the baseline system. Under quite different conditions, we have found 96.8% agreement over judges.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P92-1039",
  "title": "Right Association Revisited",
  "year": 1992,
  "venue": "ACL",
  "abstract": "Consideration of when Right Association works and when it fails lead to a restatement of this parsing principle in terms of the notion of heaviness. A computational investigation of a syntactically annotated corpus provides evidence for this proposal and suggest circumstances when RA is likely to make correct attachment predictions.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/P92-1041",
  "title": "Incremental Dependency Parsing",
  "year": 1992,
  "venue": "ACL",
  "abstract": "The paper introduces a dependency-based grammar and the associated parser and focusses on the problem of determinism in parsing and recovery from errors. First, it is shown how dependency-based parsing can be afforded, by taking into account the suggestions coming from other approaches, and the preference criteria for parsing are briefly addressed. Second, the issues of the interconnection between the syntactic analysis and the semantic interpretation in incremental processing are discussed and the adoption of a TMS for the recovery of the processing errors is suggested. ",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/P93-1007",
  "title": "A Speech-First Model for Repair Detection and Correction",
  "year": 1993,
  "venue": "ACL",
  "abstract": "Interpreting fully natural speech is an important goal for spoken language understanding systems. However, while corpus studies have shown that about 10% of spontaneous utterances contain self-corrections, or REPAIRS, little is known about the extent to which cues in the speech signal may facilitate repair processing. We identify several cues based on acoustic and prosodic analysis of repairs in a corpus of spontaneous speech, and propose methods for exploiting these cues to detect and correct repairs. We test our acoustic-prosodic cues with other lexical cues to repair identification and find that precision rates of 89-93% and recall of 78-83% can be achieved, depending upon the cues employed, from a prosodically labeled corpus.",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/P93-1025",
  "title": "Transfers of Meaning",
  "year": 1993,
  "venue": "ACL",
  "abstract": "In one form or another, the phenomena associated with \"meaning transfer\" have become central issues in a lot of recent work on semantics. Speaking very roughly, we can partition approaches to the phenomenon along two dimensions, which yield four basic points of departure. In the first two, people have considered transfer in basically semantic or linguistic terms. Some have concentrated on what we might call the paradigmatic aspects of transfer, focusing on the productive lexical processes that map semantic features into features for example, the \"grinding\" rule that applies to turn the names of animals into mass terms denoting their meat or fur. This the approach that's involved in most recent work on \"regular polysemy,\" \"systematic polysemy,\" and the like, for example by Apresjan, Ostler and Atkins, Briscoe and Copestake, Nunberg and Zaenen, Wilensky, Kilgarriff and a number of other people. Other people have emphasized the syncategorematic aspects of transfer; that is, the ways meaning shifts and specifications are coerced in the course of semantic composition. This is an approach that hass been developed in particular by James Pustejovsky and his collaborators, building on earlier work on type shifting. As opposed to these, there are conceptual and pragmatic approaches to transfer, which focus on the extralinguistic circumstances that license transfers of various types. Here again there are both paradigmatic and syncategorematic approaches, loosely speaking. The first is exemplified in a lot of recent work on metaphor by people associated with the \"cognitive linguistics\" school, which has focused chiefly on the relations between domains of experience that metaphor variously exploits and imputes. The second is represented by work on indirect speech within Gricean pragmatics, Relevance Theory, and the like, which has been chiefly concerned with specifying the conversational conditions that give rise to metaphor, irony, and analogous phenomena. Of course this categorization is somewhat factitious. The borders between these approaches are highly porous, and most work on transfer overlaps several of them. This is entirely appropriate, since these are in no sense competing theories or accounts of the phenomena. Transfer is clearly a linguistic process, and in many of its most important forms a lexical one. But it just as clearly has its basis in very general cognitive and communicative principles. And while it's reasonable that people should choose to focus on one or another of these considerations relative to their immediate interests, it is also useful to keep the Big Picture in mind, lest we inadvertently ascribe to one domain of explanation a responsibility that more properly belongs to another. This is the picture I want to sketch out in this talk. A comprehensive account of transfer has to make appeal to three different kinds of regularities or rules. The first are nonlinguistic: the correspondences between domains, real or imputed, that transfer invokes, and the communicative interests that may make these invocations useful or instructive they enable us to identify one thing in virtue of its relation to another, explain an abstract domain by reference to a concrete one, and so forth. Second, there is the repertory of general linguistic processes of transfer that exploit these correspondences and principles. By these I have in mind not traditional categories like metaphor, synecdoche, and m e t o n y m y distinctions that have basically to do with the kinds of domain correspondences that transfer exploits but the various types of operations that make possible typeshifting and sortal reassignment of expressions, syntactic recategorizations, and deferred indexical reference. These processes may cross-cut the types of domain correspondences that they exploit, and I'll show that we often find a single type of domain correspondence underlying two or more distinct semantic processes of transfer. Third, there are the language-specific instantiations of these operations, for example in the form of constructions or lexical rules that license particular types or",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/P94-1005",
  "title": "From Strings to Trees to Strings to Trees ... (Abstract)",
  "year": 1994,
  "venue": "ACL",
  "abstract": "Sentences are not just strings of words (or are they ?), they have some (hierarchical) structure. This much is accepted by all grammar formalisms. But how much structure is needed? The more the sentences are like strings the less the need for structure. A certain amount of structure is necessary simply because a clause may embed another clause, or one clause may attach to another clause or parts of it. Leaving this need of structure aside, the question then is how much structure should a (minimal) clause have? Grammar formalisms can differ significantly on this issue. Minimal clauses can be just strings, or words linked by dependencies (dependency trees), or with rich phrase structure trees, or with flat (one level) phrase structure trees (almost strings) and so on. How much hierarchical structure is needed for a minimal clause is still an open question, that is being debated heatedly. How are clauses put together? Are these operations more like string manipulations (concatenation, insertion, or wrapping, for example) or are they more like tree transformations (generalized transformations of the early transformational grammars, for example)? Curiously, the early transformational grammars, although clearly using tree transformations, actually formulated the transformations as pseudo string-like operations! More recent non-transformational grammars differ significantly with respect to their use of string rewriting or tree rewriting operations. Grammar formalisms differ with respect to their stringiness or treeness. Also during their evolution, they have gone back and forth between string-like and tree-like representations, often combining them in different ways. These swings are a reflection of the complex interplay between aspects of language structure such as constituency, dependency, dominance, locality of predicates and their arguments, adjacency, order, and discontinuity. We will discuss these issues in an informal manner, in the context of a range of formalisms.",
  "stance": -0.1
 },
 {
  "url": "https://aclanthology.org/P94-1034",
  "title": "An Automatic Treebank Conversion Algorithm for Corpus Sharing",
  "year": 1994,
  "venue": "ACL",
  "abstract": "An automatic treebank conversion method is proposed in this paper to convert a treebank into another treebank. A new treebank associated with a different grammar can be generated automatically from the old one such that the information in the original treebank can be transformed to the new one and be shared among different research communities. The simple algorithm achieves conversion accuracy of 96.4% when tested on 8,867 sentences between two major grammar revisions of a large MT system.",
  "stance": 0.9
 },
 {
  "url": "https://aclanthology.org/P94-1038",
  "title": "Similarity-Based Estimation of Word Cooccurrence Probabilities",
  "year": 1994,
  "venue": "ACL",
  "abstract": "In many applications of natural language processing it is necessary to determine the likelihood of a given word combination. For example, a speech recognizer may need to determine which of the two word combinations \"eat a peach\" and \"eat a beach\" is more likely. Statistical NLP methods determine the likelihood of a word combination according to its frequency in a training corpus. However, the nature of language is such that many word combinations are infrequent and do not occur in a given corpus. In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on \"most similar\" words. We describe a probabilistic word association model based on distributional word similarity, and apply it to improving probability estimates for unseen word bigrams in a variant of Katz 's back-off model. The similarity-based method yields a 20% perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech-recognition error.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P95-1012",
  "title": "Compiling HPSG type constraints into definite clause programs",
  "year": 1995,
  "venue": "ACL",
  "abstract": "We present a new approach to HPSG processing: compiling HPSG grammars expressed as type constraints into definite clause programs. This provides a clear and computationally useful correspondence between linguistic theories and their implementation. The compiler performs offline constraint inheritance and code optimization. As a result, we are able to efficiently process with HPSG grammars without haviog to hand-translate them into definite clause or phrase structure based systems.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/P95-1020",
  "title": "A Uniform Treatment of Pragmatic Inferences in Simple and Complex Utterances and Sequences of Utterances",
  "year": 1995,
  "venue": "ACL",
  "abstract": "Drawing appropriate defeasible inferences has been proven to be one of the most pervasive puzzles of natural language processing and a recurrent problem in pragmatics. This paper provides a theoretical framework, called stratified logic, that can accommodate defeasible pragmatic inferences. The framework yields an algorithm that computes the conversational, conventional, scalar, clausal, and normal state implicatures; and the presuppositions that are associated with utterances. The algorithm applies equally to simple and complex utterances and sequences of utterances.",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/P95-1040",
  "title": "The Effect of Pitch Accenting on Pronoun Referent Resolution",
  "year": 1995,
  "venue": "ACL",
  "abstract": "By strictest interpretation, theories of both centering and intonational meaning fail to predict the existence of pitch accented pronominals. Yet they occur felicitously in spoken discourse. To explain this, I emphasize the dual functions served by pitch accents, as markers of both propositional (semantic/pragmatic) and attentional salience. This distinction underlies my proposals about the attentional consequences of pitch accents when applied to pronominals, in particular, that while most pitch accents may weaken or reinforce a cospecifier's status as the center of attention, a contrastively stressed pronominal may force a shift, even when contraindicated by textual features.",
  "stance": -0.8
 },
 {
  "url": "https://aclanthology.org/P95-1046",
  "title": "Knowledge-based Automatic Topic Identification",
  "year": 1995,
  "venue": "ACL",
  "abstract": "As the first step in an automated text summarization algorithm, this work presents a new method for automatically identifying the central ideas in a text based on a knowledge-based concept counting paradigm. To represent and generalize concepts, we use the hierarchical concept taxonomy WordNet. By setting appropriate cutoff values for such parameters as concept generality and child-to-parent frequency ratio, we control the amount and level of generality of concepts extracted from the text.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/P96-1006",
  "title": "Integrating Multiple Knowledge Sources to Disambiguate Word Sense: An Exemplar-Based Approach",
  "year": 1996,
  "venue": "ACL",
  "abstract": "In this paper, we present a new approach for word sense disambiguation (WSD) using an exemplar-based learning algorithm. This approach integrates a diverse set of knowledge sources to disambiguate word sense, including part of speech of neighboring words, morphological form, the unordered set of surrounding words, local collocations, and verb-object syntactic relation. We tested our WSD program, named LEXAS, on both a common data set used in previous work, as well as on a large sense-tagged corpus that we separately constructed. LEXAS achieves a higher accuracy on the common data set, and performs better than the most frequent heuristic on the highly ambiguous words in the large corpus tagged with the refined senses of WoRDNET.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P96-1052",
  "title": "Towards Testing the Syntax of Punctuation",
  "year": 1996,
  "venue": "ACL",
  "abstract": "Little work has been done in NLP on the subject of punctuation, owing mainly to a lack of a good theory on which computational treatments could be based. This paper described early work in progress to try to construct such a theory. Two approaches to finding the syntactic function of punctuation marks are discussed, and procedures are described by which the results from these approaches can be tested and evaluated both against each other as well as against other work. Suggestions are made for the use of these results, and for future work.",
  "stance": -0.3
 },
 {
  "url": "https://aclanthology.org/P97-1002",
  "title": "Fast Context-Free Parsing Requires Fast Boolean Matrix Multiplication",
  "year": 1997,
  "venue": "ACL",
  "abstract": "Valiant showed that Boolean matrix multiplication (BMM) can be used for CFG parsing. We prove a dual result: CFG parsers running in time O([Gl[w[ 3-e) on a grammar G and a string w can be used to multiply m x m Boolean matrices in time O(m3-e/3). In the process we also provide a formal definition of parsing motivated by an informal notion due to Lang. Our result establishes one of the first limitations on general CFG parsing: a fast, practical CFG parser would yield a fast, practical BMM algorithm, which is not believed to exist.",
  "stance": -0.0
 },
 {
  "url": "https://aclanthology.org/P97-1003",
  "title": "Three Generative, Lexicalised Models for Statistical Parsing",
  "year": 1997,
  "venue": "ACL",
  "abstract": "In this paper we first propose a new statistical parsing model, which is a generative model of lexicalised context-free grammar. We then extend the model to include a probabilistic treatment of both subcategorisation and wh-movement. Results on Wall Street Journal text show that the parser performs at 88.1/87.5% constituent precision/recall, an average improvement of 2.3% over (Collins 96).",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P97-1011",
  "title": "Learning Features that Predict Cue Usage",
  "year": 1997,
  "venue": "ACL",
  "abstract": "Our goal is to identify the features that predict the occurrence and placement of discourse cues in tutorial explanations in order to aid in the automatic generation of explanations. Previous attempts to devise rules for text generation were based on intuition or small numbers of constructed examples. We apply a machine learning program, C4.5, to induce decision trees for cue occurrence and placement from a corpus of data coded for a variety of features previously thought to affect cue usage. Our experiments enable us to identify the features with most predictive power, and show that machine learning can be used to induce decision trees useful for text generation.",
  "stance": 0.6
 },
 {
  "url": "https://aclanthology.org/P97-1037",
  "title": "A DP-based Search Using Monotone Alignments in Statistical Translation",
  "year": 1997,
  "venue": "ACL",
  "abstract": "In this paper, we describe a Dynamic Programming (DP) based search algorithm for statistical translation and present experimental results. The statistical translation uses two sources of information: a translation model and a language model. The language model used is a standard bigram model. For the translation lnodel, the alignment probabilities are made dependent on the differences in the alignment positions rather than on the absolute positions. Thus, the approach amounts to a first-order Hidden Markov model (HMM) as they are used successfully in speech recognition for the time alignment problem. Under the assumption that the alignment is monotone with respect to the word order in both languages, an efficient search strategy for translation can be formulated. The details of the search algorithm are described. Experiments on the EuTrans corpus produced a word error rate of 5.1%.",
  "stance": 0.6
 },
 {
  "url": "https://aclanthology.org/P97-1061",
  "title": "Retrieving Collocations by Co-Occurrences and Word Order Constraints",
  "year": 1997,
  "venue": "ACL",
  "abstract": "In this paper, we describe a method for automatically retrieving collocations from large text corpora. This method retrieve collocations in the following stages: 1) extracting strings of characters as units of collocations 2) extracting recurrent combinations of strings in accordance with their word order in a corpus as collocations. Through the method, various range of collocations, especially domain specific collocations, are retrieved. The method is practical because it uses plain texts without any information dependent on a language such as lexical knowledge and parts of speech.",
  "stance": 0.9
 },
 {
  "url": "https://aclanthology.org/P99-1008",
  "title": "Finding Parts in Very Large Corpora",
  "year": 1999,
  "venue": "ACL",
  "abstract": "We present a method for extracting parts of objects from wholes (e.g. \"speedometer\" from \"car\"). Given a very large corpus our method finds part words with 55% accuracy for the top 50 words as ranked by the system. The part list could be scanned by an end-user and added to an existing ontology (such as WordNet), or used as a part of a rough semantic lexicon.",
  "stance": 0.6
 },
 {
  "url": "https://aclanthology.org/P99-1014",
  "title": "Inducing a Semantically Annotated Lexicon via EM-Based Clustering",
  "year": 1999,
  "venue": "ACL",
  "abstract": "We present a technique for automatic induction of slot annotations for subcategorization frames, based on induction of hidden classes in the EM framework of statistical estimation. The models are empirically evalutated by a general decision test. Induction of slot labeling for subcategorization frames is accomplished by a further application of EM, and applied experimentally on frame observations derived from parsing large corpora. We outline an interpretation of the learned representations as theoretical-linguistic decompositional lexical entries.",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/P99-1043",
  "title": "Mixed Language Query Disambiguation",
  "year": 1999,
  "venue": "ACL",
  "abstract": "We propose a mixed language query disambiguation approach by using co-occurrence information from monolingual data only. A mixed language query consists of words in a primary language and a secondary language. Our method translates the query into monolingual queries in either language. Two novel features for disambiguation, namely contextual word voting and 1-best contextual word, are introduced and compared to a baseline feature, the nearest neighbor. Average query translation accuracy for the two features are 81.37% and 83.72%, compared to the baseline accuracy 75.50%.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/P99-1047",
  "title": "A Decision-Based Approach to Rhetorical Parsing",
  "year": 1999,
  "venue": "ACL",
  "abstract": "We present a shift-reduce rhetorical parsing algorithm that learns to construct rhetorical structures of texts from a corpus of discourse-parse action sequences. The algorithm exploits robust lexical, syntactic, and semantic knowledge sources.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/P99-1053",
  "title": "A Syntactic Framework for Speech Repairs and Other Disruptions",
  "year": 1999,
  "venue": "ACL",
  "abstract": "This paper presents a grammatical and processing framework for handling the repairs, hesitations, and other interruptions in natural human dialog. The proposed framework has proved adequate for a collection of human-human task-oriented dialogs, both in a full manual examination of the corpus, and in tests with a parser capable of parsing some of that corpus. This parser can also correct a pre-parser speech repair identifier resulting in a 4.8% increase in recall.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P99-1057",
  "title": "Learning to Recognize Tables in Free Text",
  "year": 1999,
  "venue": "ACL",
  "abstract": "Many real-world texts contain tables. In order to process these texts correctly and extract the information contained within the tables, it is important to identify the presence and structure of tables. In this paper, we present a new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables. When tested on Wall Street Journal news documents, our learning approach outperforms a deterministic table recognition algorithm that identifies tables based on a fixed set of conditions. Our learning approach is also more flexible and easily adaptable to texts in different domains with different table characteristics.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P99-1063",
  "title": "Lexical Semantics to Disambiguate Polysemous Phenomena of Japanese Adnominal Constituents",
  "year": 1999,
  "venue": "ACL",
  "abstract": "We exploit and extend the Generative Lexicon Theory to develop a formal description of adnominal constituents in a lexicon which can deal with linguistic phenomena found in Japanese adnominal constituents. We classify the problematic behavior into \"static disambiguation\" and \"dynamic disambiguation\" tasks. Static disambiguation can be done using lexical information in a dictionary, whereas dynamic disambiguation requires inferences at the knowledge representation level.",
  "stance": 0.2
 },
 {
  "url": "https://aclanthology.org/J90-3001",
  "title": "Resolving Quasi Logical Forms",
  "year": 1990,
  "venue": "CL",
  "abstract": "The paper describes intermediate and resolved logical form representations of sentences involving referring expressions and a reference resolution process for mapping between these representations. The intermediate representation, Quasi Logical Form (or QLF), may contain unresolved terms corresponding to anaphoric noun phrases covering bound variable anaphora, reflexives, and definite descriptions. Implict relations arising in constructs such as compound nominals appear in QLF as unresolved formulae. The QLF representation is also neutral with respect to ambiguities corresponding to quantifier scope and the collective/distributive distinction, the latter being treated as quantifier resolution. Reference candidates are proposed according to an ordered set of \"reference resolution rules\" producing possible resolved logical forms to which linguistic and pragmatic constraints are then applied.",
  "stance": -0.2
 },
 {
  "url": "https://aclanthology.org/J91-1003",
  "title": "met*: A Method for Discriminating Metonymy and Metaphor by Computer",
  "year": 1991,
  "venue": "CL",
  "abstract": "The met* method distinguishes selected examples of metonymy from metaphor and from literalness and anomaly in short English sentences. In the met* method, literalness is distinguished because it satisfies contextual constraints that the nonliteral others all violate. Metonymy is discriminated from metaphor and anomaly in a way that [1] supports Lakoff and Johnson's (1980) view that in metonymy one entity stands for another whereas in metaphor one entity is viewed as another, [2] permits chains of metonymies (Reddy 1979), and [3] allows metonymies to co-occur with instances of either literalness, metaphor, or anomaly. Metaphor is distinguished from anomaly because the former contains a relevant analogy, unlike the latter. The met* method is part of Collative Semantics, a semantics for natural language processing, and has been implemented in a computer program called meta5. Some examples of meta5's analysis of metaphor and metonymy are given. The met* method is compared with approaches from artificial intelligence, linguistics, philosophy, and psychology.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/J91-3002",
  "title": "Chinese Number-Names, Tree Adjoining Languages, and Mild Context-Sensitivity",
  "year": 1991,
  "venue": "CL",
  "abstract": "The Tree Adjoining Grammar formalism, both its singleas well as multiple-component versions, has recently received attention as a basis for the description and explication of natural language. We show in this paper that the number-name system of Chinese is generated neither by this formalism nor by any other equivalent or weaker ones, suggesting that such a task might require the use of the more powerful Indexed Grammar formalism. Given that our formal results apply only to a proper subset of Chinese, we extensively discuss the issue of whether they have any implications for the whole of that natural language. We conclude that our results bear directly either on the syntax of Chinese or on the interface between Chinese and the cognitive component responsible for arithmetic reasoning. Consequently, either Tree Adjoining Grammars, as currently defined, fail to generate the class of natural languages in a way that discriminates between linguistically warranted sublanguages, or formalisms with generative power equivalent to Tree Adjoining Grammar cannot serve as a basis for the interface between the human linguistic and mathematical faculties.",
  "stance": -0.8
 },
 {
  "url": "https://aclanthology.org/J94-1002",
  "title": "A Hierarchical Stochastic Model for Automatic Prediction of Prosodic Boundary Location",
  "year": 1994,
  "venue": "CL",
  "abstract": "Prosodic phrase structure provides important information for the understanding and naturalness of synthetic speech, and a good model of prosodic phrases has applications in both speech synthesis and speech understanding. This work describes a statistical model of an embedded hierarchy of prosodic phrase structure, motivated by results in linguistic theory. Each level of the hierarchy is modeled as a sequence of subunits at the next level, with the lowest level of the hierarchy representing factors such as syntactic branching and prosodic constituent length using a binary tree classification. A maximum likelihood solution for parameter estimation is presented, allowing automatic training of different speaking styles. For predicting prosodic phrase breaks from text, a dynamic programming algorithm is given for finding the maximum probability prosodic parse. Experimental results on a corpus of radio news demonstrate a high rate of success for predicting major and minor phrase boundaries from text without syntactic information (81% correct prediction with 4% false prediction).",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/J95-2002",
  "title": "An Efficient Probabilistic Context-Free Parsing Algorithm that Computes Prefix Probabilities",
  "year": 1995,
  "venue": "CL",
  "abstract": "We describe an extension of Earley's parser for stochastic context-free grammars that computes the following quantities given a stochastic context-free grammar and an input string: a) probabilities of successive prefixes being generated by the grammar; b) probabilities of substrings being generated by the nonterminals, including the entire string being generated by the grammar; c) most likely (Viterbi) parse of the string; d) posterior expected number of applications of each grammar production, as required for reestimating rule probabilities. Probabilities (a) and (b) are computed incrementally in a single left-to-right pass over the input. Our algorithm compares favorably to standard bottom-up parsing methods for SCFGs in that it works efficiently on sparse grammars by making use of Earley's top-down control structure. It can process any context-free rule format without conversion to some normal form, and combines computations for (a) through (d) in a single algorithm. Finally, the algorithm has simple extensions for processing partially bracketed inputs, and for finding partial parses and their likelihoods on ungrammatical inputs.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/J96-1004",
  "title": "From Conceptual Time to Linguistic Time",
  "year": 1996,
  "venue": "CL",
  "abstract": "In this paper, we present a method for generating French texts conveying temporal information that integrates Discourse Representation Theory (DRT) and Systemic Grammar Theory. DRT is used to represent temporal information and an intermediate semantic level for the temporal localization expressed by temporal adverbial phrases and verb phrases. This representation is then translated into a syntactic form using Systemic Grammar Theory. We have implemented this method in a working prototype called Prdtexte.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/J96-2004",
  "title": "Assessing Agreement on Classification Tasks: The Kappa Statistic",
  "year": 1996,
  "venue": "CL",
  "abstract": "Currently, computational linguists and cognitive scientists working in the area of discourse and dialogue argue that their subjective judgments are reliable using several different statistics, none of which are easily interpretable or comparable to each other. Meanwhile, researchers in content analysis have already experienced the same difficulties and come up with a solution in the kappa statistic. We discuss what is wrong with reliability measures as they are currently used for discourse and dialogue work in computational linguistics and cognitive science, and argue that we would be better off as afield adopting techniques from content analysis.",
  "stance": -0.8
 },
 {
  "url": "https://aclanthology.org/J97-3006",
  "title": "Current theories of centering for pronoun interpretation: a critical evaluation",
  "year": 1997,
  "venue": "CL",
  "abstract": "We review the fundamental concepts of centering theory and discuss some facets of the pronoun interpretation problem that motivate a centering-style analysis. We then demonstrate some problems with a popular centering-based approach with respect to these motivations.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/J98-1002",
  "title": "Similarity-based Word Sense Disambiguation",
  "year": 1998,
  "venue": "CL",
  "abstract": "We describe a method for automatic word sense disambiguation using a text corpus and a machinereadable dictionary (MRD). The method is based on word similarity and context similarity measures. Words are considered similar if they appear in similar contexts; contexts are similar if they contain similar words. The circularity of this definition is resolved by an iterative, converging process, in which the system learns from the corpus a set of typical usages for each of the senses of the polysemous word listed in the MRD. A new instance of a polysemous word is assigned the sense associated with the typical usage most similar to its context. Experiments show that this method can learn even from very sparse training data, achieving over 92% correct disambiguation performance.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/J98-1004",
  "title": "Automatic Word Sense Discrimination",
  "year": 1998,
  "venue": "CL",
  "abstract": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/J98-2002",
  "title": "Generalizing Case Frames Using a Thesaurus and the MDL Principle",
  "year": 1998,
  "venue": "CL",
  "abstract": "A new method for automatically acquiring case frame patterns from large corpora is proposed. In particular, the problem of generalizing values of a case frame slot for a verb is viewed as that of estimating a conditional probability distribution over a partition of words, and a new generalization method based on the Minimum Description Length (MDL) principle is proposed. In order to assist with efficiency, the proposed method makes use of an existing thesaurus and restricts its attention to those partitions that are present as \"cuts\" in the thesaurus tree, thus reducing the generalization problem to that of estimating a \"tree cut model\" of the thesaurus tree. An efficient algorithm is given, which provably obtains the optimal tree cut model for the given frequency data of a case slot, in the sense of MDL. Case frame patterns obtained by the method were used to resolve PP-attachment ambiguity. Experimental results indicate that the proposed method improves upon or is at least comparable with existing methods.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/J98-4002",
  "title": "Selective Sampling for Example-based Word Sense Disambiguation",
  "year": 1998,
  "venue": "CL",
  "abstract": "This paper proposes an efficient example sampling method for example-based word sense disambiguation systems. To construct a database of practical size, a considerable overhead for manual sense disambiguation (overhead for supervision) is required. In addition, the time complexity of searching a large-sized database poses a considerable problem (overhead for search). To counter these problems, our method selectively samples a smaller-sized effective subset from a given example set for use in word sense disambiguation. Our method is characterized by the reliance on the notion of training utility: the degree to which each example is informative for future example sampling when used for the training of the system. The system progressively collects examples by selecting those with greatest utility. The paper reports the effectiveness of our method through experiments on about one thousand sentences. Compared to experiments with other example sampling methods, our method reduced both the overhead for supervision and the overhead for search, without the degeneration of the performance of the system.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/J98-4005",
  "title": "Letter to the Editor: Clues from the Depth Hypothesis: A Reply to Geoffrey Sampson's Review",
  "year": 1998,
  "venue": "CL",
  "abstract": "In linguistics it has not been possible to use the standard criteria and assumptions of science because the ancients placed our discipline not in the physical domain but in the logical domain where concepts and theories do not represent parts of the natural world. Many of the problems facing linguistics follow inevitably, for example the difficulties that linguistics experiences in agreeing on grammatical theory. One symptom is the long-standing difficulty in testing the depth hypothesis, which came out of early MT research. Sampson (1997) attempted recently to test the depth hypothesis by a computer analysis of a grammatically annotated corpus of English. It is shown that this attempted test and his attempt at defending the testability of the dept h hypothesis are invalid. But clues from the depth hypothesis have led to new foundations for general linguistics put forth in the book (Yngve 1996) that Sampson (1998) reviewed. This work reconstitutes linguistics in the physical domain where the criteria and assumptions of science can be applied. Sampson's review of this book contains a number of serious errors and inaccuracies.",
  "stance": -0.5
 },
 {
  "url": "https://aclanthology.org/J99-4006",
  "title": "Conceptions of limited attention and discourse focus",
  "year": 1999,
  "venue": "CL",
  "abstract": "Walker (1996) presents a cache model of the operation of attention in the processing of discourse as an alternative to the focus space stack that was proposed previously by Grosz and Sidner (Grosz 1977a; Grosz and Sidner 1986). In this squib, we present a critical analysis of the cache model and of Walker's supporting evidence from anaphora in discourses with interruptions and from informationally redundant utterances. We argue that the cache model is underdetermined in several ways that are crucial to a comparison of the two models and conclude that Walker has not established the superiority of the cache model. We also argue that psycholinguistic evidence does not support the cache model over the focus stack model.",
  "stance": -0.9
 },
 {
  "url": "https://aclanthology.org/P84-1054",
  "title": "On Parsing Preferences",
  "year": 1984,
  "venue": "COLING",
  "abstract": "It is argued that syntactic preference principles such as Right Association and Minimal Attachment are unsatisfactory as usually formulated. Among the difficulties are: (I) dependence on ill-specified or implausible principles of parser operation; (2) dependence on questionable assumptions about syntax; (3) lack Of provision, even in principle, for integration with semantic and pragmatic preference principles; and (4) apparent counterexamples, even when discounting (I)-(3). A possible approach to a solution is sketched.",
  "stance": -0.1
 },
 {
  "url": "https://aclanthology.org/P84-1071",
  "title": "What Not to Say",
  "year": 1984,
  "venue": "COLING",
  "abstract": "A problem with most text production and language generation systems is that they tend to become rather verbose. This may be due to negleetion of the pragmatic factors involved in communication. In this paper, a text production system, COMMENTATOR, is described and taken as a starting point for a more general discussion of some problems in Computational Pragmatics. A new line of research is suggested, based on the concept of unification.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C86-1067",
  "title": "A Kana-Kanji Translation System for Non-Segmented Input Sentences Based on Syntactic and Semantic Analysis",
  "year": 1986,
  "venue": "COLING",
  "abstract": "This paper presents a disambiguation approach for t ransla t ing non-segmented-Kana into Kanji. The method consists of two steps. In the first step, an input sentence is analyzed morphologically and ambiguous morphemes are stored in a network form. In the second step, the best path, which is a string of morphemes, is selected by syntactic and semantic analysis based on case grammar. In order to avoid the combinatorial explosion of possible paths, the following heuristic search method is adopted. First, a path that contains the smallest number of weighted-morphemes is chosen as the quasi-best path by a best-first-search technique. Next, the restricted range of morphemes near the quasi-best path is extracted from the morpheme network to construct preferential paths. An experimental system incorporating large dictionaries has been developed and evaluated. A translat ion accracy of 90.5% was obtained. This can be improved to about 95% by optimizing the dictionaries.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/C86-1128",
  "title": "A PROLOG Implementation of Government-Binding Theory",
  "year": 1986,
  "venue": "COLING",
  "abstract": "A parser which is founded on Chomsky's Government-Binding Theory and implemented in PROLOG is described. By focussing on systems of constraints as proposed by this theory, the system is capable of parsing without an elaborate rule set and subcategorization features on lexical items. In addition to the parse, theta, binding, and control relations are determined simultaneously.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/C88-1011",
  "title": "A System for Creating and Manipulating Generalized Wordclass Transition Matrices From Large Labelled Text-Corpora",
  "year": 1988,
  "venue": "COLING",
  "abstract": "This paper deals with the training phase of a Markov-type linguistic model that is based on transition probabilities between pairs and triplets of syntactic categories. To determine the optimal level of detail for a set of syntactic classes we developed a system that uses a set-theoretical formalism to defiue such sets mid has some measures to compare and optimize them individually. In section two we describe the optimization problem (hi terms of piediction, infoimation and economy requilements) and our approach to its solution. Section three introduces the system dlat will assist a linguist in handling the prediction and economy criteria and in the last section we present some sample results that can be achieved with it.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C88-1040",
  "title": "Robust parsing of severely corrupted spoken utterances",
  "year": 1988,
  "venue": "COLING",
  "abstract": "This paper describes a technique for enabling a speech understanding system to deal with sentences for which some monosyllabic words are not recognized. Such words are supposed to act as mere syntactic markers within the system linguistic domain. This result is achieved by combining a modified caseframe approach to linguistic knowledge representation with a parsing strategy able to integra te expectat ions from the language model and predictions from words. Experimental results show that the proposed technique permits to greatly increase the quota of corrupted sentences correctly understandable without sensibly decreasing parsing efficiency.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C88-1049",
  "title": "Chart Parsing According to the Slot and Filler Principle",
  "year": 1988,
  "venue": "COLING",
  "abstract": "A parser is an algorithm that assigns a structural description to a string according to a grammar. It follows from this definition that there are three general issues in parser design: the structure to be assigned, the type of grammar, the recognition algorithm. Common parsers employ phrase structure descriptions, rule-based grammars, and derivation or transition oriented recognition. The following choices result in a new parser: The structure to be assigned to the input is a dependency tree with lexical, morpho-syntactic and functional-syntactic information associated with each node and coded by complex categories which are subject to unification. The grammar is lexicalized, i.e. the syntactical relationships are stated as part of the lexical descriptions of the elements of the language. The algorithm relies on the slot and filler principle in order to draw up complex structures. It utilizes a well-formed substring table (chart) which allows for discontinuous segments.",
  "stance": 0.1
 },
 {
  "url": "https://aclanthology.org/C88-1070",
  "title": "Schema Method: A Framework for Correcting Grammatically Ill-formed Input",
  "year": 1988,
  "venue": "COLING",
  "abstract": "The schema method is a framework for correcting grammatically ill-formed input. In a natural language processing system ill-formed input cannot be overlooked. A computer assisted instruction (CAI) system, in particular, needs to show the user's errors. This framework diagnoses ill-formed input, corrects it and explains the error, if an input is ill-formed. The framework recognizes a sentence at two steps: first parses weak grammar, and then strongly filters the parsed sentence. When it is known what sentences are passed by the filter, it can be used even if it is imperfect. As the strong filter, a new method is used: an interpretation schema and an interpretation rule. An interpretation schema collects input information schemata and then an interpretat ion rule judges whether the collected schemata are correct or incorrect. This approach overcomes the problem of relaxation control, the major drawback of the previous syntactically-oriented methods, and is also more efficient.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C88-1082",
  "title": "Linguistic Processing Using a Dependency Structure Grammar for Speech Recognition and Understanding",
  "year": 1988,
  "venue": "COLING",
  "abstract": "This paper proposes an efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar. The strategy includes parsing and phrase prediction algorithms. After speech processing and phrase recognition based on phoneme recognition, the parser extracts the sentence with the best likelihood taking account of the phonetic likelihood of phrase candidates and the linguistic likelihood of the semantic inter-phrase dependency relationships. A fast parsing algorithm using breadth-first search is also proposed. The predictor pre-selects the p}~.ase candidates using transition rules combined with a dependency structure to reduce the amount of phonetic processing. The proposed linguistic processor has been tested through speech recognition experiments. The experimental results show that it greatly increases the accuracy of speech recognitions, and the breadth-first parsing algorithm and predictor increase processing speed.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C90-2026",
  "title": "GPSG Parsing, Bidirectional Charts, and Connection Graphs",
  "year": 1990,
  "venue": "COLING",
  "abstract": "This paper describes a tractable method for parsing GPSG grammars without altering the modularity and expressiveness of this formalism. The proposed method is based on a constraint propagation mechanism which reduces the number of unnecessary structures built at parse time through the early detection of inadmissible local trees. The propagation of constraints is rendered efficient by indexing constraints and categories in a connection graph and by using a bidirectional chart parser together with a bottomup strategy centered around head constituents. ",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/C90-2061",
  "title": "A Type-theoretical Analysis of Complex Verb Generation",
  "year": 1990,
  "venue": "COLING",
  "abstract": "Tense and aspect, together with mood and modality, usually form the entangled structure of a complex verb. They are often hard to translate by machines, because of both syntactic and semantic differences between languages. This problem seriously affects upon the generation process because those verb components in interlingua are hardly rearranged correctly in the target language. We propose here a method in which each verb element is defined as a mathematical function according to its type of type theory. This formalism gives each element its legal position in the complex verb in the target language and certifies so-called partial translation. In addition, the generation algorithm is totally free from the stepwise calculation, and is available on parallel architecture.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C90-3019",
  "title": "Organizing linguistic knowledge for multilingual generation",
  "year": 1990,
  "venue": "COLING",
  "abstract": "We propose an architecture for the organisation of linguistic knowledge which allows to (1) separately formulate generalizations for different types of linguistic information, and (2) state interrelations between partial information belonging to different levels of description. We use typed feature structures for encoding linguistic knowledge. We show the application of this representational device for the architecture of linguistic knowledge sources for multilingual generation. As an example, we describe the use of interacting collocational and syntactic constraints in the generation of French and German sentences.",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/C90-3035",
  "title": "Expressive Power of Grammatical Formalisms",
  "year": 1990,
  "venue": "COLING",
  "abstract": "We propose formalisms and concepts which allow to make precise the m'gmnents in controversies over the adequacy of competing models of language, and over their formal equivalence.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/C90-3087",
  "title": "Corpus Work With Pc Beta",
  "year": 1990,
  "venue": "COLING",
  "abstract": "PC Beta is a PC oriented tool for corpus work in this term's broadest possible sense. With PC Beta one can prepare texts for corpus work, e.g. standardize texts in different ways (very important when texts from different sources together will constitute a corpus), one can process texts, and one can analyze texts. Making ordinary concordances and similar things with PC Beta is, of course, very simple, and, in fact, PC Beta gives \"concordance making\" a new dimension. One can perform morphological analyses, one can use PC Beta as a \"tagger\", i.e. provide the words with different kinds of tags. In all, PC Beta is a versatile program, and it is in many cases the only program needed (together with functions belonging to the MS/PC-DOS operative system) for pursuing a complete corpus project. The program's main distinctive feature is simplicity: it is rule controlled, and the rules adhere to a format that any linguist can learn to understand very quickly. But beware, in spite of its innocent appearence the program is a little tiger.",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/C92-1009",
  "title": "Feature Structure Based Semantic Head Driven Generation",
  "year": 1992,
  "venue": "COLING",
  "abstract": "This paper proposes a generation method for feature structure based unification grammars. As compared with fixed arity term notation, feature structure notation is more flexible for representing knowledge needed to generate idiomatic structures as well as general constructions. The method enables feature structure retrieval via multiple indices. The indexing mechanism, when used with a semantic head driven generation algorithm, attains efficient generation even when a large amount of generation knowledge must be considered. Our method can produce all possible structures in parallel, using structure sharing among ambiguous substructures. ",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/C92-1032",
  "title": "Left-Corner Parsing and Psychological Plausibility",
  "year": 1992,
  "venue": "COLING",
  "abstract": "It is well known that even extremely limited centerembedding causes people to have difficulty in comprehension, but that leftand right-branching constractions produce no such effect. If the difficulty in comprehension is taken to be a result of processing load, as is widely assumed, then measuring the processing load induced by a parsing strategy on these constructions may help determine its plausibility as a psychological model. On this basis, it has been argued [AJ91, JL83] that by identifying processing load with space utilization, we can rule out both top-down and bottom-up parsing as viable candidates for the human sentence processing mechanism, attd that left-corner parsing represents a plausible alternative. Examining their arguments in detail, we find difficulties with each presentation. In this paper we revise the argument and validate its central claim. In so doing, we discover that the key distinction between the parsing methods is not the form of prediction (top-down vs. bottom-up vs. leftcorner), but rather the ability to instantiate the operation of composition.",
  "stance": -0.6
 },
 {
  "url": "https://aclanthology.org/C92-1033",
  "title": "TTP: A Fast and Robust Parser for Natural Language",
  "year": 1992,
  "venue": "COLING",
  "abstract": "In this paper we describe TTP , a fast and robust natural language parser which can analyze written text and generate regularized parse structures for sentences and phrases at the speed of approximately 0.5 sec/sentence, or 44 word per second. The parser is based on a wide coverage grammar for English, developed by the New York University's Linguistic String Project, and it uses the machine-readable version of the Oxford Advanced Learner's Dictionary as a source of its basic vocabulary. The parser operates on stochastically tagged text, and contains a powerful skip-and-fit recovery mechanism that allows it to deal with extra-grammatical input and to operate effectively under a severe time pressure. Empirical experiments, testing parser's speed and accuracy, were performed on several collections: a collection of technical abstracts (CACM-3204), a corpus of news messages (MUC-3), a selection from ACM Computer Library database, and a collection of Wall Street Journal articles, approximately 50 million words in total.",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/C92-1047",
  "title": "Une ontologie du temps pour le langage naturel",
  "year": 1992,
  "venue": "COLING",
  "abstract": "We propose a new ontology for the time in natural language which provides the following features : - it renders an account of most of the temporal phenomena of language (dates, duration, events, states) ; it offers capacities for the comprehension of the narratives ; - in the contrary to the traditional systems, it needs no hard \"types\" for dealing with the different classes used by the terminology : thus an event may date others \"when John died, there were many demonstrations in the world\", a date may be the beginning of an event \"monthly, Paul was leaving for a six months tour\" ; our ontology endures the fluidity of natural language which does not make rigid, in the narratives, the signification of the temporal entities ; - it allows some multiplicity of points of viev, (partially inconsistent) about a single event : in the sentence \"the travel of Christophe Colomb, which endured a long time, has been the beginning of a rich period of exploration\", \"the voyage of CC\" is seen as a simple event in the main proposition and as a complex event in the subordinate one. With respect to these issues, the ontology uses the following frameworks : - a KLONE-like network aiming at a quick detection of incoherences : it contains taxonomic inferences (including the whole terminology) plus the facts ; a bulk of rules (assertional device) embodying contingent properties ; - non-monotonic reasoning is needed to revise simplistic conclusions obtained from superficial descriptions : the rules and the links of the network may be default rules ; - the VaDe (Variable Depth) system supports our ontology ; it is implemented with an ATMS-like truth maintenance system. The flexible ontology we present offers an interesting frame for further researches in computational linguistics, in particular in the domain of the interpretation of the narratives.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C92-2071",
  "title": "Un Systeme Inferentiel Oriente Objet Pour Des Applications En Langues Naturelles",
  "year": 1992,
  "venue": "COLING",
  "abstract": "Up to now, there is still no specific model for solving the problem of natured language representation and reasoning. In this paper, we propose an object oriented formalism for supporting knowledge representation, extraction and exploitation in the context of natural language processing. In the natural language analysis, this system is situated after the morpho-syntax and the linguistic semantics. It represents two classes of concepts: objects of discourse and action schemata, the former resulting from nominal syntagms and the latter from the 'processes'. We are concerned here just by the  representation of objects. In the natural language discourse, manipulated objects ,are complex objects and the reasoning is by nature first inferential and then deductive. To take into account this kind of reasoning we need a suitable representation: a model of inferential objects. The theoretical foundations of the proposed model are Lesniewski's logical systems: tile Calculus of Names and the Mereology. The former is based on a primitive functor called \"epsilon\" interpreted as is-a, the latter is based on a part-of relation which is called the \"ingredience\". The whole system is supported by these two primitives and theirs derived functions. The concepts of our model result from a collaboration between linguists and computer scientists. The main concepts are the intensional and extensional universes, notions and types. The possible inferential reasoning can be of different types : it can concern the status, the denominations, the structures or the \"fonctifs\" of the objects.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/C92-2087",
  "title": "Logical Form of Hierarchical Relation on Verbs and Extracting it from Definition Sentences in a Japanese Dictionary",
  "year": 1992,
  "venue": "COLING",
  "abstract": "We are studying how to extract hierarchical relation on verbs from definition sentences in a Japanese dictionary. The hierarchical relation on verbs has been dealt with as a binary relation on verbs, but it should be dealt with as logical relation on predicates. We will define the logical form of the hierarchical relation on verbs and then discuss which part of the syntactic structure of the definition sentence represents that relation. We will call the main predicate verb in this part the definition verb. Furthermore we will describe how to semiautomatically select the proper meaning of the definition verb and the proper correspondence between cases of an entry verb and the definition verb in order to extract the hierarchical relation as logical relation.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C92-2100",
  "title": "A Three-level Revision Model for Improving Japanese Bad-styled Expressions",
  "year": 1992,
  "venue": "COLING",
  "abstract": "This paper proposes a three-level revision model for improving badly-styled Japanese expressions, especially in the field of technical communication. The model is a mixture of the regeneration-based model and tile rewriting-based model. The first level divides long sentences, while the second level improves several badly-styled expressions with iterative partial rewriting operations. The last level performs regeneration, in which word ordering and punctuation to reduce the reading ambiguity are currently involved. Experimental results show that our model is effective in realizing practical revision support systems.",
  "stance": 0.9
 },
 {
  "url": "https://aclanthology.org/C92-2121",
  "title": "Semantic Network Array Processor as a Massively Parallel Computing Platform for High Performance and Large-Scale Natural Language Processing",
  "year": 1992,
  "venue": "COLING",
  "abstract": "This paper demonstrates the utility of the Semantic Network Array Processor (SNAP) as a massively parallel platform for high performance and large-scale natural language processing systems. SNAP is an experimental massively parallel machine which is dedicated to, but not limited to, the natural language processing using semantic networks. In designing the SNAP, we have investigated various natural language processing systems and theories to determine the scope of the hardware support and a set of micro-coded instructions to be provided. As a result, SNAP employs an extended markerpassing model and a dynamically modifiable network model. A set of primitive instructions is micro-coded to directly support a parallel marker-passing, bit-operations, numeric operations, network modifications, and other essential functions for natural language processing. This paper demonstrates the utility of SNAP for various paradigms of natural language processing. We have discovered that the SNAP provides milliseconds or microseconds performance on several important applications such as the memory-based parsing and translation, classification-based parsing, and VLKB search. Also, we argue that there are numerous opportunities in the NLP community to take advantages of the comlmtational power of the SNAP.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/C92-3150",
  "title": "Surface Grammatical Analysis for the Extraction of Terminological Noun Phrases",
  "year": 1992,
  "venue": "COLING",
  "abstract": "LEXTER is a software package for extracting terminology. A corpus of French language texts on any subject field is fed in, and LEXTER produces a list of likely terminological units to be submitted to an expert to be validated. To identify the terminological units, LEXTER takes their form into account and proceeds in two main stages : analysis, parsing. In the first stage, LEXTER uses a base of rules designed to identify frontier markers in view to analysing the texts and extracting maximal length noun phrases. In the second stage, LEXTER parses these maximal-length noun phrases to extract subgroups which by virtue of their grammatical structure and their place in the maximal-length noun phrases are likely to be terminological units. In this article, the type of analysis used (surface grammatical analysis) is highlighted, as the methodological approach adopted to adapt the rules (experimental approach).",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C92-3161",
  "title": "Shalt2- a Symmetric Machine Translation System with Conceptual Transfer",
  "year": 1992,
  "venue": "COLING",
  "abstract": "Shal l2 is a knowledge-based machine translation system with a symmetric architecture. The grammar rules, mapping rules between syntactic and conceptual (semantic) representations, and transfer rules for conceptual paraphrasing are all bi-directional knowledge sources used by both a parser and a generator.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/C92-4206",
  "title": "Multimodal Database Query",
  "year": 1992,
  "venue": "COLING",
  "abstract": "The paper proposes a mult imodal interface for a real sales database application. We show how natural language processing may be integrated with a visual, direct manipulat ion method of database query, to produce a user interface which supports a flexible form of query specification, provides implicit guidance about the coverage of the linguistic component, and allows more focused discourse reference.",
  "stance": 0.6
 },
 {
  "url": "https://aclanthology.org/C94-1023",
  "title": "AUTOMATIC MODEL REFINEMENT - with an application to tagging",
  "year": 1994,
  "venue": "COLING",
  "abstract": "Statistical NLP models usually only consider coarse information and very restricted context to make the estimation of parameters feasible. To reduce the modeling error introduced by a simplified probabilistic model, the Classitication and Regression Tree (CART) method was adopted in this paper to select more discriminative features for automatic model refinement. Because the features are adopted dependently during splitting the classification tree in CART, the number of training data in each terminal node is small, which makes the labeling process of terminal nodes not robust. This over-tuning phenomenon cannot be completely removed by crossvalidation process (i.e., pruning process). A probabilistic classification model based on the selected discriminative features is thus proposed to use the training data more efficiently. In tagging the Brown Corpus, our probabilistic classification model reduces the error rate of the top 10 error dominant words from 5.71% to 4.35%, which shows 23.82% improvement over the unrefined model.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/C94-1032",
  "title": "A Stochastic Japanese Morphological Analyzer Using a Forward-DP Backward-A* N-Best Search Algorithm",
  "year": 1994,
  "venue": "COLING",
  "abstract": "We present a novel method for segmenting the input sentence into words and assigning parts of speech to the words. It consists of a statistical language model and an efficient two-pass N-best search algorithm. The algorithm does not require delimiters between words. Thus it is suitable for written Japanese. The proposed Japanese morphological analyzer achieved 95.1% recall and 94.6% precision for open text when it was trained and tested on the ATR Corpus.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C94-1075",
  "title": "A Modular Architecture for Constraint-Based Parsing",
  "year": 1994,
  "venue": "COLING",
  "abstract": "This paper presents a framework and a system for implementing, comparing and analyzing parsers for some classes of Constraint-Based Grammars. The framework consists in a uniform theoretic description of parsing algorithms, and provides the structure for decomposing the system into logical components, with possibly several interchangeable implementations. Many parsing algorithms can be obtained by composition of the modules of our system. Modularity is also, a way of achieving code sharing for the common parts of these various algorithms. Furthermore, the design helps reusing the existing modules when implementing other algorithms. The system uses the flexible modularity provided by the programming languages Alcool-90, based on a type system that ensures the safety of module composition.",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/C94-1079",
  "title": "PRINCIPAR - An Efficient, Broad-coverage, Principle-based Parser",
  "year": 1994,
  "venue": "COLING",
  "abstract": "We present an efI]cient, broad-coverage, principle-based parser for English. The parser has been implemented in C++ and runs on SUN Sparcstations with X-windows. It conrains a lexicon with over 90,000 entries, constructed automatically by applying a set of extraction and conversion rules to entries from machine readable dictionaries.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/C94-2106",
  "title": "A System of Verbal Semantic Attributes Focused on the Syntactic Correspondence between Japanese and English",
  "year": 1994,
  "venue": "COLING",
  "abstract": "This paper proposes a system of 97 verbal semantic attributes for Japanese verbs which considers both dynamic characteristics and the relationship of verbs to cases. These attribute values are used to disambiguate the meanings of all Japanese and English pattern pairs in a Japanese to English transfer pattern dictionary consisting of 15,000 pairs of Japanese valence patterns and equivalent English syntactic structures.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/C94-2138",
  "title": "A Reestimation Algorithm for Probabilistic ttecursive Transition Network",
  "year": 1994,
  "venue": "COLING",
  "abstract": "Probabilistic Recursive Transition Network (PRTN) is an elevated version of RTN to model and process languages in stochastic parameters. The representation is a direct derivation from the RTN and keeps much the spirit of Hidden Markov Model at the same time. We present a reestimation algorithm for PRTN that is a variation of InsideOutside algorithm that computes the values of the probabilistic parameters from sample sentences (parsed or unparsed). ",
  "stance": 0.2
 },
 {
  "url": "https://aclanthology.org/C94-2149",
  "title": "XTAG System - A Wide Coverage Grammar for English",
  "year": 1994,
  "venue": "COLING",
  "abstract": "This paper presents the XTAG system, a grammar development tool based on the Tree Adjoining Grammar (TAG) formalism that includes a wide-coverage syntactic grammar for English. The various components of the system are discussed and preliminary evaluation results from the parsing of various corpora are given. Results from the comparison of X3AG against the IBM statistical parser and the Alvey Natural Language Tool parser are also given.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C94-2153",
  "title": "An Efficient Syntactic Tagging Tool for Corpora",
  "year": 1994,
  "venue": "COLING",
  "abstract": "The tree bank is an important resources for MT and linguistics researches, but it requires that large number of sentences be annotated with syntactic information. It is time consuming and troublesome, and difficult to keep consistency, if annotation is done manually. In this paper, we presented a new technique for the semi-automatic tagging of Chinese text. The system takes as input Chinese text, and outputs the syntactically tagged sentence(dependency tree). We use dependency grammar and employ a stack based shift/reduce context-dependent parser as the tagging mechanism. The system works in human-machine cooperative way, in which the machine can acquire tagging rules from human intervention. The automation level can be improved step by step by accumulating rules during annotation. In addition, good consistency of tagging is guaranteed.",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/C94-2177",
  "title": "Reverse Queries in DATR",
  "year": 1994,
  "venue": "COLING",
  "abstract": "DATR is a declarative representation language for lexical information and as such, in principle, neutral with respect to particular processing strategies. Previous DATR compiler/interpreter systems support only one access strategy that closely resembles the set, of inference rules of the procedural semantics of DATR (Evans Gazdar 1989a). In this paper we present an alternative access strategy (reverse query strategy) for a nontrivial subset of DATR.",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/C94-2212",
  "title": "NL Understanding with a Grammar of Constructions",
  "year": 1994,
  "venue": "COLING",
  "abstract": "We present an approach to natural language understanding based on a computable grammar of constructions. A construction consists of a set of features of form and a description of meaning in a context. A grammar is a set of constructions. This kind of grammar is the key element of MINCAL, an implemented natural language speech-enabled interface to an online calendar system. The architecture has two key aspects: (a) the use of constructions, integrating descriptions of form, meaning and context into one whole; and (b) the separation of domain knowledge (about calendars) from application knowledge (about the particular on-line calendar).",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C96-1006",
  "title": "Extracting Word Correspondences from Bilingual Corpora Based on Word Co-occurrence Information",
  "year": 1996,
  "venue": "COLING",
  "abstract": "A new method has been developed for extracting word correspondences from a bilingual corpus. First, the co-occurrence information for each word in both languages is extracted from the corpus. Then, the correlations between the co-occurrence features of the words are calculated pairwisely with the assistance of a basic word bilingual dictionary. Finally, the pairs of words with the highest correlations are output selectively. This method is applicable to rather small, unaligned corpora; it can extract correspondences between compound words as well as simple words. An experiment using bilingual patent-specification corpora achieved 28% recall and 76% precision; this demonstrates that the method effectively reduces the cost of bilingual dictionary augmentation.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C96-1069",
  "title": "An Automatic Clustering of Articles Using Dictionary Definitions",
  "year": 1996,
  "venue": "COLING",
  "abstract": "In this paper, we propose a statistical approach for clustering of artMes using on-line dictionary definitions. One of the characteristics of our approach is that every sense of word in ar tMes is automatically disambiguated using dictionary definitions. The other is that in order to cope with the problem of a phrasal lexicon, linking which links words with their semantically similar words in articles is introduced in our method. The results of experiments demonstrate the effectiveness of the proposed method.",
  "stance": 0.9
 },
 {
  "url": "https://aclanthology.org/C96-1086",
  "title": "Inherited Feature-based Similarity Measure Based on Large Semantic Hierarchy and Large Text Corpus",
  "year": 1996,
  "venue": "COLING",
  "abstract": "We describe a similarity calculation model called IFSM (Inherited Feature Similarity Measure) between objects (words/concepts) based on their common and distinctive features. We propose an implementation method for obtaining features based on abstracted triples extracted fi'om a large text eorpus utilizing taxonomical knowledge. This model represents an integration of traditional methods, i.e,. relation based simlarity measure and distribution based similarity measure. An experiment, using our new concept abstraction method which we call the flat probability grouping method, over 80,000 surface triples, shows that the abstraction level of 3000 is a good basis for feature description.",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/C96-1087",
  "title": "A Probabilistic Approach to Compound Noun Indexing in Korean Texts",
  "year": 1996,
  "venue": "COLING",
  "abstract": "In this paper we address the problem of compound noun indexing that is about segmenting or decomposing compound nouns into promising index terms. Compound nouns as index terms that usually subscribe to specific notions tend to increase the precision of retrieval performance. The use of the component nouns of a compound noun as index terms, on the other hand, may improve the recall performance, but can decrease the precision. Our proposed method to handle compound nouns with a goal to increase the recall while preserving the precision computes the relevance of the component nouns of a compound noun to the document content by comparing the document sets that are supported by the component nouns and the terms of the document. The operational content of a term is represented as the probabilistic distribution of the term over the document set. Experiments with a set of 1,000 documents show that our method gains 33% increase of retrieval performance compared to the indexing method without compound noun analysis, and is as good as manual decomposition by human experts.",
  "stance": 0.2
 },
 {
  "url": "https://aclanthology.org/C96-1089",
  "title": "Learning Bilingual Collocations by Word-Level Sorting",
  "year": 1996,
  "venue": "COLING",
  "abstract": "This paper proposes a new method for learning bilingual collocations from sentence aligned parallel corpora. Our method comprises two steps: (1) extracting useful word chunks (n-grams) by word-level sorting and (2) constructing bilingual collocations by combining the word chunks acquired in stage (1). We apply the method to a very challenging text pair: a stock market bulletin in Japanese and its abstract in English. Domain specific collocations are well captured even if they were not contained in the dictionaries of economic terms. ",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/C96-2098",
  "title": "Extraction of Lexical Translations from Non-Aligned Corpora",
  "year": 1996,
  "venue": "COLING",
  "abstract": "A method for extracting lexical translations from non-aligned corpora is proposed to cope with the unavailability of large aligned corpus. The assumption that \"translations of two co-occurring words in a source language also co-occur in the target language\" is adopted and represented in the stochastic matrix formulation. The translation matrix provides the co-occurring information translated from the source into the target. This translated co-occurring information should resemble that of the original in the target when the ambiguity of the translational relation is resolved. An algorithm to obtain the best translation matrix is introduced. Some experiments were performed to evaluate the effectiveness of the ambiguity resolution and the refinement of the dictionary.",
  "stance": 0.6
 },
 {
  "url": "https://aclanthology.org/C96-2102",
  "title": "Towards a Syntactic Account of Punctuation",
  "year": 1996,
  "venue": "COLING",
  "abstract": "Little notice has been taken of punctuation in the field of natural language processing, chiefly due to the lack of any coherent theory on which to base implementations. Some work has been carried out concerning punctuation and parsing, but much of it seems to have been rather ad-hoc and performance-motivated. This paper describes the first step towards the construction of a theoretically-motivated account of punctuation. Parsed corpora are processed to extract punctuation patterns, which are then checked and generalised to a small set of General Punctuation Rules. Their usage is discussed, and suggestions are made for possible methods of including punctuation information in grammars.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/C96-2110",
  "title": "Identifying the Coding System and Language of On-line Documents on the Internet",
  "year": 1996,
  "venue": "COLING",
  "abstract": "This paper proposes a new algorithm that simultaneously identifies the coding system and language of a code string fetched from the Internet, especially World-Wide Web. The algorithm uses statistic language models to select the correctly decoded string as well as to determine the language. The proposed algorithm covers 9 languages and 11 coding systems used in Eastern Asia and Western Europe. Experimental results show that the level of accuracy of our algorithm is over 95% for 640 on-line documents.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C96-2114",
  "title": "Linguistic Indeterminacy as a Source of Errors in Tagging",
  "year": 1996,
  "venue": "COLING",
  "abstract": "Most evaluations of part-of-speech tagging compare the utput of an automatic tagger to some established standard, define the differences as tagging errors and try to remedy them by, e.g., more training of the tagger. The present article is based on a manual analysis of a large number of tagging errors. Some clear patterns among the errors can be discerned, and the sources of the errors as well as possible alternative methods of remedy are presented and discussed. In particular are the problems with undecidable cases treated.",
  "stance": 0.1
 },
 {
  "url": "https://aclanthology.org/C96-2144",
  "title": "A Constraint-based Case Frame Lexicon",
  "year": 1996,
  "venue": "COLING",
  "abstract": "We present a constraint based case frame lexicon architecture for bidirectional mapping between a syntactic case frame and a semantic frame. The lexicon uses a semantic sense as the basic unit and employs a multitiered constraint structure for the resolution of syntactic information into the appropriate senses and/or idiomatic usage. Valency changing transformations such as morphologically marked passivized or causativized forms are handled via lexical rules that manipulate case frames templates. The system has been implemented in a typed-feature system and applied to Turkish. ",
  "stance": 0.2
 },
 {
  "url": "https://aclanthology.org/C96-2145",
  "title": "Error-tolerant Tree Matching",
  "year": 1996,
  "venue": "COLING",
  "abstract": "This paper presents an efficient algorithm for retrieving from a database of trees, all trees that match a given query tree approximately, that is, within a certain error tolerance. It has natural language processing applications in searching for matches in example-based translation systems, and retrieval from lexical databases containing entries of complex feature structures. The algorithm has been implemented on SparcStations, and for large randomly generated synthetic tree databases (some having tens of thousands of trees) it can associatively search for trees with a small error, in a matter of tenths of a second to few seconds.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/C98-1021",
  "title": "Spoken Dialogue Interpretation with the DOP Model",
  "year": 1998,
  "venue": "COLING",
  "abstract": "We show how the DOP model can be used for fast and robust processing of spoken input in a practical spoken dialogue system called OVIS. OVIS, Openbaar Vervoer Informatie Systeem (\"Public Transport Information System\"), is a Dutch spoken language information system which operates over ordinary telephone lines. The prototype system is the immediate goal of the NWO 1 Priority Programme \"Language and Speech Technology\". In this paper, we extend the original DOP model to context-sensit ive interpretation of spoken input. The system we describe uses the OVIS corpus (10,000 trees enriched with compositional semantics) to compute from an input word-graph the best utterance together with its meaning. Dialogue context is taken into account by dividing up the OVIS corpus into context-dependent subcorpora. Each system question triggers a subcorpus by which the user answer is analyzed and interpreted. Our experiments indicate that the context-sensitive DOP model obtains better accuracy than the original model, allowing for fast and robust processing of spoken input.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C98-1048",
  "title": "Experiments with Learning Parsing Heuristics",
  "year": 1998,
  "venue": "COLING",
  "abstract": "Any large language processing software relies in its operation on heuristic decisions concerning the strategy of processing. These decisions are usually \"hard-wired\" into the software in the form of handcrafted heuristic rules, independent of the nature of the processed texts. We propose an alternative, adaptive approach in which machine learning techniques learn the rules from examples of sentences in each class. We have experimented with a variety of learning techniques on a representative instance of this problem within the realm of parsing. Our approach lead to the discovery of new heuristics that perform significantly better than the current hand-crafted heuristic. We discuss the entire cycle of application of machine learning and suggest a methodology for the use of machine learning as a technique for the adaptive optimisation of language-processing software.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C98-1087",
  "title": "Long Distance Pronominalisation and Global Focus",
  "year": 1998,
  "venue": "COLING",
  "abstract": "1) Out corpus of descriptive text contains a significant number of long-distance pronominal references (8.4% of the total). In order to account for how these pronouns are interpreted, we re-examine Grosz and Sidner's theory of the attentional state, and in particular the use of the global focus to supplement centering theory. Our corpus evidence concerning these long-distance pronominal references, as well as studies of the use of descriptions, proper names and ambiguous uses of pronouns, lead us to conclude that a discourse focus stack mechanism of the type proposed by Sidner is essential to account for the use of these referring expressions. We suggest revising the Grosz & Sidner fl'amework by allowing for the possibility that an entity in a focus space may have special status.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/C98-1106",
  "title": "Term-list Translation using Mono-lingual Word Co-occurrence Vectors",
  "year": 1998,
  "venue": "COLING",
  "abstract": "A term-list is a list of content words that characterize a consistent text or a concept. This paper presents a new method for translating a term-list by using a corpus in the target language. The method first retrieves alternative translations for each input word from a bilingual dictionary. It then determines the most 'coherent' combination of alternative translations, where the coherence of a set of words is defined as the proximity among multi-dimensional vectors produced from the words on the basis of co-occurrence statistics. The method was applied to term-lists extracted from newspaper articles and achieved 81% translation accuracy for ambiguous words (i.e., words with multiple translations).",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/C98-2119",
  "title": "Word Clustering and Disambiguation Based on Co-occurrence Data",
  "year": 1998,
  "venue": "COLING",
  "abstract": "We address the problem of clustering words (or constructing a thesaurus) based on co-occurrence data, and using the acquired word classes to improve the accuracy of syntactic disambiguation. We view this problem as that of estimating a joint probability distribution specifying the joint probabilities of word pairs, such as noun verb pairs. We propose an efficient algorithm based on the Minimum Description Length (MDL) principle for estimating such a probability distribution. Our method is a natural extension of those proposed in (Brown et al., 1992) and (Li and Abe, 1996), and overcomes their drawbacks while retaining their advantages. We then combined this clustering method with the disambiguation method of (Li and Abe, 1995) to derive a disambiguation method that makes use of both automatically constructed thesauruses and a hand-made thesaurus. The overall disambiguation accuracy achieved by our method is 85.2%, which compares favorably against the accuracy (82.4%) obtained by the state-of-the-art disambiguation method of (Brill and Resnik, 1994).",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C98-2120",
  "title": "Identifying Syntactic Role of Antecedent in Korean Relative Clause Using Corpus and Thesaurus Information",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper describes an approach to identifying the syntactic role of an antecedent in a Korean relative clause, which is essential to structural disambiguation and semantic analysis. In a learning phase, linguistic knowledge such as conceptual co-occurrence patterns and syntactic role distribution of antecedents is extracted from a large-scale corpus. Then, in an application phase, the extracted knowledge is applied in determining the correct syntactic role of an antecedent in relative clauses. Unlike previous research based on co-occurrence patterns at the lexical level, we represent co-occurrence patterns with concept types in a thesaurus. In an experiment, the proposed method showed a high accuracy rate of 90.4% in resolving ambiguities of syntactic role determination of antecedents.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/C98-2145",
  "title": "An Estimate of Referent of Noun Phrases in Japanese Sentences",
  "year": 1998,
  "venue": "COLING",
  "abstract": "In machine translation and man-machine dialogue, it is important to clarify referents of noun phrases. We present a method for determining the referents of noun phrases in Japanese sentences by using the referential properties, modifiers, and possessors 1 of noun phrases. Since the Japanese language has no articles, it is difficult to decide whether a noun phrase has an antecedent or not. We had previously estimated the referential properties of noun phrases that correspond to articles by using clue words in the sentences (Murata and Nagao 1993). By using these referential properties, our system determined the referents of noun phrases ill Japanese sentences. Furthermore we used the modifiers and possessors of noun phrases in determining the referents of noun phrases. As a result, on training sentences we obtained a precision rate of 82% and a recall rate of 85% in the determination of the referents of noun phrases that have antecedents. On test sentences, we obtained a precision rate of 79% and a recall rate of 77%.",
  "stance": 0.7
 },
 {
  "url": "https://aclanthology.org/C98-2147",
  "title": "Japanese OCR Error Correction using Character Shape Similarity and Statistical Language Model",
  "year": 1998,
  "venue": "COLING",
  "abstract": "We present a novel OCR error correction method for languages without word delimiters that have a large character set, such as Japanese and Chinese. It consists of a statistical OCR model, an approximate word matching method using character shape similarity, and a word segmentation algorithm using a statistical language model. By using a statistical OCR model and character shape similarity, the proposed error corrector outperforms the previously published method. When the baseline character recognition accuracy is 90%, it achieves 97.4% character recognition accuracy.",
  "stance": 0.9
 },
 {
  "url": "https://aclanthology.org/C98-2154",
  "title": "An Efficient Parallel Substrate for Typed Feature Structures on Shared Memory Parallel Machines",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper describes an efficient parallel system for processing Typed Feature Structures (TFSs) on shared-memory parallel machines. We call the system Parallel Substrate for TFS (PSTFS). PSTFS is designed for parallel computing environments where a large number of agents are working and communicating with each other. Such agents use PSTFS as their low-level module for solving constraints on TFSs and sending/receiving TFSs to/from other agents in an efficient manner. From a programmers point of view, PSTFS provides a simple and unified mechanism for building high-level parallel NLP systems. The performance and the flexibility of our PSTFS are shown through the experiments on two different types of parallel HPSG parsers. The speed-up was more than 10 times on both parsers.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/C98-2158",
  "title": "Recognition of the Coherence Relation between Te-linked Clauses",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper describes a method for recognizing coherence relations between clauses which are linked by te in Japanese a translational equivalent of English and. We consider that the coherence relations are categories each of which has a prototype structure as well as the relationships among them. By utilizing this organization of the relations, we can infer an appropriate relation from the semantic structures of the clauses between which that relation holds. We carried out an experiment and obtained the correct recognition ratio of 82% for the 280 sentences.",
  "stance": 0.9
 },
 {
  "url": "https://aclanthology.org/C98-2159",
  "title": "On the Evaluation and Comparison of Taggers: the Effect of Noise in Testing Corpora.",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper addresses the issue of Pos tagger evaluation. Such evaluation is usually performed by comparing the tagger output with a reference test corpus, which is resumed to be error-free. Currently used corpora contain noise which causes the obtained performance to be a distortion of the real value. We analyze to what extent this distortion may invalidate the comparison between taggers or the measure of the improvement given by a new system. The main conclusion is that a more rigorous testing experimentation setting/designing is needed to reliably evaluate and compare tagger accuracies.",
  "stance": -0.8
 },
 {
  "url": "https://aclanthology.org/C98-2162",
  "title": "Machine Aided Error-Correction Environment for Korean Morphological Analysis and Part-of-Speech Tagging",
  "year": 1998,
  "venue": "COLING",
  "abstract": "Statistical methods require very large corpus with high quality. But building large and faultless annota ted corpus is a very difficult job. This paper proposes an efficient method to construct part-of-speech tagged corpus. A rulebased error correction method is proposed to find and correct errors semi-automatical ly by user-defined rules. We also make use of user's correction log to reflect feedback. Experiments were carried out to show the efficiency of error correction process of this workbench. The result shows that about 63.2 % of tagging errors can be corrected.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C98-2176",
  "title": "Building Accurate Semantic Taxonomies Monolingual MRDs",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper presents a method that combines a set of unsupervised algorithms in order to accurately build large taxonomies from any machine-readable dictionary (MRD). Our aim is to profit from conventional MRDs, with no explicit semantic coding. We propose a system that 1) performs fully automatic extraction of taxonomic links from MRD entries and 2) ranks the extracted relations in a way that selective manual refinement is allowed. Tested accuracy can reach around 100% depending on the degree of coverage selected, showing that taxonomy building is not limited to structured dictionaries such as LDOCE.",
  "stance": 0.9
 },
 {
  "url": "https://aclanthology.org/C98-2202",
  "title": "Keyword Extraction using Term-Domain Interdependence for Dictation of Radio News",
  "year": 1998,
  "venue": "COLING",
  "abstract": "In this paper, we propose keyword extraction method for dictation of radio news which consists of several domains. In our method, newspaper articles which are automatically classified into suitable domains are used in order to calculate feature vectors. The feature vectors shows term-domain interdependence and are used for selecting a suitable domain of each part of radio news.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/C98-2216",
  "title": "Modeling with Structures in Statistical Machine Translation",
  "year": 1998,
  "venue": "COLING",
  "abstract": "Most statistical machine translation systems employ a word-based alignment model. In this paper we demonstrate that word-based align: ment is a major cause of translation errors. We propose a new alignment model based on shallow phrase structures, and the structures can be automatically acquired from parallel corpus. This new model achieved over 10% error reduction for our spoken language translation task.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/C98-2223",
  "title": "Word Sense Disambiguation using Optimised Combinations of Knowledge Sources",
  "year": 1998,
  "venue": "COLING",
  "abstract": "Word sense disambiguation algorithms, with few exceptions, have made use of only one lexical knowledge source. We describe a system which performs word sense disambiguation on all content words in free text by combining different knowledge sources: semantic preferences, dictionary definitions and subject/domain codes along with part-of-speech tags, optimised by means of a learning algorithm. We also describe the creation of a new sense tagged corpus by combining existing resources. Tested accuracy of our approach on this corpus exceeds 92%, demonstrating the viability of all-word disambiguation rather than restricting oneself to a small sample.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/P98-1004",
  "title": "A Simple Hybrid Aligner for Generating Lexical Correspondences in Parallel Texts",
  "year": 1998,
  "venue": "COLING",
  "abstract": "We present an algorithm for bilingual word alignment that extends previous work by treating multi-word candidates on a par with single words, and combining some simple assumptions about the translation process to capture alignments for low frequency words. As most other alignment algorithms it uses cooccurrence statistics as a basis, but differs in the assumptions it makes about the translation process. The algorithm has been implemented in a modular system that allows the user to experiment with different combinations and variants of these assumptions. We give performance results from two evaluations, which compare well with results reported in the literature.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P98-1018",
  "title": "Consonant Spreading in Arabic Stems",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper examines the phenomenon of consonant spreading in Arabic stems. Each spreading involves a local surface copying of an underlying consonant, and, in certain phonological contexts, spreading alternates productively with consonant lengthening (or gemination). The morphophonemic triggers of spreading lie in the patterns or even in the roots themselves, and the combination of a spreading root and a spreading pattern causes a consonant to be copied multiple times. The interdigitation of Arabic stems and the realization of consonant spreading are formalized using finite-state morphotactics and variation rules, and this approach has been successfully implemented in a large-scale Arabic morphological analyzer which is available for testing on the Internet.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/P98-1022",
  "title": "A Probabilistic Corpus-Driven Model for Lexical-Functional Analysis",
  "year": 1998,
  "venue": "COLING",
  "abstract": "We develop a Data-Oriented Parsing (DOP) model based on the syntactic representations of Lexical-Functional Grammar (LFG). We start by summarizing the original DOP model for tree representations and then show how it can be extended with corresponding functional structures. The resulting LFG-DOP model triggers a new, corpus-based notion of grammaticality, and its probability models exhibit interesting behavior with respect to specificity and the interpretation of ill-formed strings.",
  "stance": 0.1
 },
 {
  "url": "https://aclanthology.org/P98-1040",
  "title": "Dialogue Management in Vector-Based Call Routing",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper describes a domain independent, automatically trained call router which directs customer calls based on their response to an open-ended \"How may I direct your call?\" query. Routing behavior is trained from a corpus of transcribed and hand-routed calls and then carried out using vector-based information retrieval techniques. Based on the statistical discriminating power of the n-gram terms extracted from the caller's request, the caller is 1) routed to the appropriate destination, 2) transferred to a human operator, or 3) asked a disambiguation question. In the last case, the system dynamically generates queries tailored to the caller's request and the destinations with which it is consistent. Our approach is domain independent and the training process is fully automatic. Evaluations over a financial services call center handling hundreds of activities with dozens of destinations demonstrate a substantial improvement on existing systems by correctly routing 93.8% of the calls after punting 10.2% of the calls to a human operator.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P98-1061",
  "title": "A Structure-sharing Parser for Lexicalized Grammars",
  "year": 1998,
  "venue": "COLING",
  "abstract": "In wide-coverage lexicalized grammars many of the elementary structures have substructures in common. This means that in conventional parsing algorithms some of the computation associated with different structures is duplicated. In this paper we describe a precompilation technique for such grammars which allows some of this computation to be shared. In our approach the elementary structures of the grammar are transformed into finite state automata which can be merged and minimised using standard algorithms, and then parsed using an automatonbased parser. We present algorithms for constructing automata from elementary structures, merging and minimising them, and string recognition and parse recovery with the resulting grammar.",
  "stance": 0.4
 },
 {
  "url": "https://aclanthology.org/P98-1111",
  "title": "Unlimited Vocabulary Grapheme to Phoneme Conversion for Korean TTS",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules. The method consists of mainly four modules including morpheme normalization, phrase-break detection, morpheme to phoneme conversion and phoneme connectivity check. The morpheme normalization is to replace non-Korean symbols into standard Korean graphemes. The phrase-break detector assigns phrase breaks using part-of-speech (POS) information. In the morpheme-to-phoneme conversion module, each morpheme in the phrase is converted into phonetic patterns by looking up the morpheme phonetic pattern dictionary which contains candidate phonological changes in boundaries of the morphemes. Graphemes within a morpheme are grouped into CCV patterns and converted into phonemes by the CCV conversion rules. The phoneme connectivity table supports grammaticality checking of the adjacent two phonetic morphemes. In the experiments with a corpus of 4,973 sentences, we achieved 99.9% of the graphemeto-phoneme conversion performance and 97.5% of the sentence conversion performance. The full Korean TTS system is now being implemented using this conversion method.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P98-1113",
  "title": "A Flexible Example-Based Parser Based on the SSTC",
  "year": 1998,
  "venue": "COLING",
  "abstract": "In this paper we sketch an approach for Natural Language parsing. Our approach is an example-based approach, which relies mainly on examples that already parsed to their representation structure, and on the knowledge that we can get from these examples the required information to parse a new input sentence. In our approach, examples are annotated with the Structured String Tree Correspondence (SSTC) annotation schema where each SSTC describes a sentence, a representation tree as well as the correspondence between substrings in the sentence and subtrees in the representation tree. In the process of parsing, we first try to build subtrees for phrases in the input sentence which have been successfully found in the example-base a bottom up approach. These subtrees will then be combined together to form a single rooted representation tree based on an example with similar representation structure a top down approach.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/P98-2145",
  "title": "Text Segmentation with Multiple Surface Linguistic Cues",
  "year": 1998,
  "venue": "COLING",
  "abstract": "In general, a certain range of sentences in a text, is widely assumed to form a coherent unit which is called a discourse segment. Identifying the segment boundaries is a first step to recognize the structure of a text. In this paper, we describe a method for identifying segment boundaries of a Japanese text with the aid of multiple surface linguistic cues, though our experiments might be small-scale. We also present a method of training the weights for multiple linguistic cues automatically without the overfitting problem.",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/P98-2148",
  "title": "A Stochastic Language Model using Dependency and its Improvement by Word Clustering",
  "year": 1998,
  "venue": "COLING",
  "abstract": "In this paper, we present a stochastic language model for Japanese using dependency. The prediction unit in this model is all attribute of \"bunsetsu\". This is represented by the product of the head of content words and that of function words. The relation between the attributes of \"bunsetsu\" is ruled by a context-free grammar. The word sequences axe predicted from the attribute using word n-gram model. The spell of Unknow word is predicted using character n-grain model. This model is robust in that it can compute the probability of an arbitrary string and is complete in that it models from unknown word to dependency at the same time.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/P98-2187",
  "title": "A Generative Lexicon Perspective for Adjectival Modification",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper presents a semantic interpretation of adjectival modification in terms of the Generative Lexicon. It highlights the elements which can be borrowed from the GL and develops limitations and extensions. We show how elements of the Qualia structure can be incorporated into semantic composition rules to make explicit the semantics of the combination adjective + noun.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/P98-2226",
  "title": "Translating Idioms",
  "year": 1998,
  "venue": "COLING",
  "abstract": "This paper discusses the treatment of fixed word expressions developed for our ITS-2 French-English translation system. This treatment makes a clear distinction between compounds i.e. multiword expressions of X°-level in which the chunks are adjacent and idiomatic phrases i.e. multiword expressions of phrasal categories, where the chunks are not necessarily adjacent. In our system, compounds are handled during the lexical analysis, while idioms are treated in the syntax, where they are treated as \"specialized lexemes\". Once recognized, an idiom can be transfered according to the specifications of the bilingual dictionary. We will show several cases of transfer to corresponding idioms in the target language, or to simple lexemes. The complete system, including several hundreds of compounds and idioms can be consulted on the Internet (http ://latl.unige.ch/itsweb.html).",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/P98-2247",
  "title": "Detecting Verbal Participation in Diathesis Alternations",
  "year": 1998,
  "venue": "COLING",
  "abstract": "We present a method for automatically identifying verbal participation in diathesis alternations. Automatically acquired subcategorization frames are compared to a hand-crafted classification for selecting candidate verbs. The minimum description length principle is then used to produce a model and cost for storing the head noun instances from a training corpus at the relevant argument slots. Alternating subcategorization frames are identified where the data from corresponding argument slots in the respective frames can be combined to produce a cheaper model than that produced if the data is encoded separately. I.",
  "stance": 0.0
 },
 {
  "url": "https://aclanthology.org/W98-1211",
  "title": "Linguistic Theory in Statistical Language Learning",
  "year": 1998,
  "venue": "CoNLL",
  "abstract": "This article attempts to determine what elements of linguistic theory are used in statistical language learning, and why the extracted language models look like they do. The study indicates that some linguistic elements, such as the notion of a word, are simply too useful to be ignored. The second most important factor seems to be features inherited from the original task for which the technique was used, for example using hidden Markov models for partof-speech tagging, rather than speech recognition. The two remaining important factors are properties of the runtime processing scheme employing the extracted language model, and the properties of the available corpus resources to which the statistical learning techniques are applied. Deliberate attempts to include linguistic theory seem to end up in a fifth place.",
  "stance": 0.2
 },
 {
  "url": "https://aclanthology.org/W98-1227",
  "title": "A Method of Incorporating Bigram Constraints into an LR Table and Its Effectiveness in Natural Language Processing",
  "year": 1998,
  "venue": "CoNLL",
  "abstract": "In this paper, we propose a method for constructing bigram LR tables by way of incorporating bigram constraints into an LR table. Using a bigram LR table, it is possible for a GLR parser to make use of both big'ram and CFG constraints in natural language processing. Applying bigram LR tables to our GLR method has the following advantages: (1) Language models utilizing bigzam LR tables have lower perplexity than simple bigram language models, since local constraints (higram) and global constraints (CFG) are combined in a single bigram LR table. (2) Bigram constraints are easily acquired from a given corpus. Therefore data sparseness is not likely to arise. (3) Separation of local and global constraints keeps down the number of CFG rules. The first advantage leads to a reduction in complexity, and as the result, better performance in GLR parsing. Our experiments demonstrate the effectiveness of our method.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/W99-0706",
  "title": "Learning Transformation Rules to Find Grammatical Relations",
  "year": 1999,
  "venue": "CoNLL",
  "abstract": "Grammatical relationships are an important level of natural language processing. We present a trainable approach to find these relationships through transformation sequences and-error-driven learning. Our approach finds grammatical relationships between core syntax groups and bypasses much of the parsing phase. On our training and test set, our procedure achieves 63.6% recall and 77.3% precision (f-score = 69.8).",
  "stance": 0.8
 },
 {
  "url": "https://aclanthology.org/W97-0321",
  "title": "Word Sense Disambiguation Based on Structured Semantic Space",
  "year": 1997,
  "venue": "EMNLP",
  "abstract": "In this paper, we propose a framework, structured semantic space, as a foundation for word sense disarnbiguation tasks, and present a strategy to identify the correct sense of a word in some context based on the space. The semantic space is a set of multidimensional real-valued vectors, which formally describe the contexts of words. Instead of locating all word senses in the space, we only make use of mono-sense words to outline it. We design a merging procedure to establish the dendrogram structure of the space and give an heuristic algorithm to find the nodes (sense clusters) corresponding with sets of similar senses in the dendrogram. Given a word in a particular context' the context would activate some clusters in the dendrogram, based on its similarity with the contexts of the words in the clusters, then the correct sense of the word could be determined by comparing its definitions with those of the words in the clusters.",
  "stance": 0.3
 },
 {
  "url": "https://aclanthology.org/W98-1503",
  "title": "Aligning Clattses in Parallel Texts",
  "year": 1998,
  "venue": "EMNLP",
  "abstract": "This paper describes a method for the automatic alignment of parallel texts at clause level. The method features statistical techniques coupled with shallow linguistic processing. It presupposes a parallel bilingual corpus and identifies alignments between the clauses of the source and target language sides of the corpus. Parallel texts are first statistically aligned at sentence level and then tagged with their part-of-speech categories. Regular grammars functioning on tags, recognize clauses on both sides of the parallel text. A probabilistic model is applied next, operating on the basis of word occurrence and co-occurrence probabilities and character lengths. Depending on sentence size, possible alignments arc fed into a dynamic progranuning framework or a simulated annealing system in order to find or approximate the best alignment. 1he method has been tested on a Small English-Greek corpus consisting of texts relevant to software systems and has produced promising results in terms of correctly identified clause alignments.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/W98-1509",
  "title": "An Empirical Approach to Text Categorization Based on Term Weight Learning",
  "year": 1998,
  "venue": "EMNLP",
  "abstract": "In this paper, we propose a method for text categorization task using term weight learning. In our approach, learning is to learn true keywords from the error of clustering results. Parameters of term weighting are then estimated so as to maximize the true keywords and minimize the other words in the text. The characteristic of our approach is that the degree of context dependency is used in order to judge whether a word in a text is a true keyword or not. The experiments using Wall Street Journal corpus demonstrate the effectiveness of the method.",
  "stance": 0.5
 },
 {
  "url": "https://aclanthology.org/W99-0615",
  "title": "HMM Specialization with Selective Lexicalization",
  "year": 1999,
  "venue": "EMNLP",
  "abstract": "We present a technique which complements Hidden Markov Models by incorporating some lexicalized states representing syntactically uncommon words. 'Our approach examines the distribution of transitions, selects the uncommon words, and makes lexicalized states for the words. We perfor'med a part-of-speech tagging experiment on the Brown corpus to evaluate the resultant language model and discovered that this technique improved the tagging accuracy by 0.21% at the 95% level of confidence.",
  "stance": 1.0
 },
 {
  "url": "https://aclanthology.org/W99-0630",
  "title": "Automatically Merging Lexicons that have Incompatible Part-of-Speech Categories",
  "year": 1999,
  "venue": "EMNLP",
  "abstract": "We present a new method to automatically merge lexicons that employ different incompatible POS categories. Such incompatibilities have hindered efforts to combine lexicons to maximize coverage with reasonable human effort. Given an \"original lexicon\", our method is able to merge lexemes from an \"additional lexicon\" into the original lexicon, converting lexemes from the additional lexicon with about 89% precision. This level of precision is achieved with the aid of a device we introduce called an anti-lexicon, which neatly summarizes all the essential information we need about the co-occurrence of tags and lemmas. Our model is intuitive, fast, easy to implement, and does not require heavy computational resources nor training corpus.",
  "stance": 0.9
 },
 {
  "url": "https://papers.neurips.cc/paper/1990/file/41ae36ecb9b3eee609d05b90c14222fb-Paper.pdf",
  "title": "A Short-Term Memory Architecture for the Learning of Morphophonemic Rules",
  "year": 1990,
  "venue": "NeurIPS",
  "abstract": "Despite its successes, Rumelhart and McClelland's (1986) well-known approach to the learning of morphophonemic rules suffers from two deficiencies: (1) It performs the artificial task of associating forms with forms rather than perception or production. (2) It is not constrained in ways that humans learners are. This paper describes a model which addresses both objections. Using a simple recurrent architecture which takes both forms and \"meanings\" as inputs, the model learns to generate verbs in one or another \"tense\", given arbitrary meanings, and to recognize the tenses of verbs. Furthermore, it fails to learn reversal processes unknown in human language.",
  "stance": -0.2
 },
 {
  "url": "https://papers.neurips.cc/paper/1990/file/5a4b25aaed25c2ee1b74de72dc03c14e-Paper.pdf",
  "title": "Designing Linear Threshold Based Neural Network Pattern Classifiers",
  "year": 1990,
  "venue": "NeurIPS",
  "abstract": "The three problems that concern us are identifying a natural domain of pattern classification applications of feedforward neural networks, selecting an appropriate feedforward network architecture, and assessing the tradeoff between network complexity, training set size, and statistical reliability as measured by the probability of incorrect classification. We close with some suggestions, for improving the bounds that come from VapnikChervonenkis theory, that can narrow, but not close, the chasm between theory and practice.",
  "stance": 0.2
 },
 {
  "url": "https://papers.neurips.cc/paper/1990/file/9de6d14fff9806d4bcd1ef555be766cd-Paper.pdf",
  "title": "Simple Spin Models for the Development of Ocular Dominance Columns and Iso-Orientation Patches",
  "year": 1990,
  "venue": "NeurIPS",
  "abstract": "Simple classical spin models well-known to physicists as the ANNNI and Heisenberg XY Models. in which long-range interactions occur in a pattern given by the Mexican Hat operator. can generate many of the structural properties characteristic of the ocular dominance columns and iso-orientation patches seen in cat and primate visual cortex.",
  "stance": 0.1
 },
 {
  "url": "https://papers.neurips.cc/paper/1990/file/c058f544c737782deacefa532d9add4c-Paper.pdf",
  "title": "Connectionist Approaches to the Use of Markov Models for Speech Recognition",
  "year": 1990,
  "venue": "NeurIPS",
  "abstract": "Previous work has shown the ability of Multilayer Perceptrons (MLPs) to estimate emission probabilities for Hidden Markov Models (HMMs). The advantages of a speech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. This paper presents results on the speaker-dependent portion of DARPA's English language Resource Management database. Results support the previously reported utility of MLP probability estimation for continuous speech recognition. An additional approach we are pursuing is to use MLPs as nonlinear predictors for autoregressive HMMs. While this is shown to be more compatible with the HMM formalism, it still suffers from several limitations. This approach is generalized to take account of time correlation between successive observations, without any restrictive assumptions about the driving noise.",
  "stance": -0.2
 },
 {
  "url": "https://papers.neurips.cc/paper/1990/file/eed5af6add95a9a6f1252739b1ad8c24-Paper.pdf",
  "title": "The Devil and the Network: What Sparsity Implies to Robustness and Memory",
  "year": 1990,
  "venue": "NeurIPS",
  "abstract": "Robustness is a commonly bruited property of neural networks; in particular, a folk theorem in neural computation asserts that neural networks-in contexts with large interconnectivity-continue to function efficiently, albeit with some degradation, in the presence of component damage or loss. A second folk theorem in such contexts asserts that dense interconnectivity between neural elements is a sine qua non for the efficient usage of resources. These premises are formally examined in this communication in a setting that invokes the notion of the \"devil\" 1 in the network as an agent that produces sparsity by snipping connections.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1991/file/55a7cf9c71f1c9c495413f934dd1a158-Paper.pdf",
  "title": "Fast Learning with Predictive Forward Models",
  "year": 1991,
  "venue": "NeurIPS",
  "abstract": "A method for transforming performance evaluation signals distal both in space and time into proximal signals usable by supervised learning algorithms, presented in [Jordan & Jacobs 90], is examined. A simple observation concerning differentiation through models trained with redundant inputs (as one of their networks is) explains a weakness in the original architecture and suggests a modification: an internal world model that encodes action-space exploration and, crucially, cancels input redundancy to the forward model is added. Learning time on an example task, cartpole balancing, is thereby reduced about 50 to 100 times.",
  "stance": 0.6
 },
 {
  "url": "https://papers.neurips.cc/paper/1991/file/8d34201a5b85900908db6cae92723617-Paper.pdf",
  "title": "Benchmarking Feed-Forward Neural Networks: Models and Measures",
  "year": 1991,
  "venue": "NeurIPS",
  "abstract": "Existing metrics for the learning performance of feed-forward neural networks do not provide a satisfactory basis for comparison because the choice of the training epoch limit can determine the results of the comparison. I propose new metrics which have the desirable property of being independent of the training epoch limit. The efficiency measures the yield of correct networks in proportion to the training effort expended. The optimal epoch limit provides the greatest efficiency. The learning performance is modelled statistically, and asymptotic performance is estimated. Implementation details may be found in (Harney, 1992).",
  "stance": 1.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1992/file/48ab2f9b45957ab574cf005eb8a76760-Paper.pdf",
  "title": "Analogy-- Watershed or Waterloo? Structural alignment and the development of connectionist models of analogy",
  "year": 1992,
  "venue": "NeurIPS",
  "abstract": "Neural network models have been criticized for their inability to make use of compositional representations. In this paper, we describe a series of psychological phenomena that demonstrate the role of structured representations in cognition. These findings suggest that people compare relational representations via a process of structural alignment. This process will have to be captured by any model of cognition, symbolic or subsymbolic.",
  "stance": 0.3
 },
 {
  "url": "https://papers.neurips.cc/paper/1992/file/9cf81d8026a9018052c429cc4e56739b-Paper.pdf",
  "title": "Metamorphosis Networks: An Alternative to Constructive Models",
  "year": 1992,
  "venue": "NeurIPS",
  "abstract": "Given a set oft raining examples, determining the appropriate number of free parameters is a challenging problem. Constructive learning algorithms attempt to solve this problem automatically by adding hidden units, and therefore free parameters, during learning. We explore an alternative class of algorithms-called metamorphosis algorithms-in which the number of units is fixed, but the number of free parameters gradually increases during learning. The architecture we investigate is composed of RBF units on a lattice, which imposes flexible constraints on the parameters of the network. Virtues of this approach include variable subset selection, robust parameter selection, multiresolution processing, and interpolation of sparse training data.",
  "stance": 0.3
 },
 {
  "url": "https://papers.neurips.cc/paper/1992/file/a532400ed62e772b9dc0b86f46e583ff-Paper.pdf",
  "title": "Weight Space Probability Densities in Stochastic Learning: II. Transients and Basin Hopping Times",
  "year": 1992,
  "venue": "NeurIPS",
  "abstract": "In stochastic learning, weights are random variables whose time evolution is governed by a Markov process. At each time-step, n, the weights can be described by a probability density function P(w, n). We summarize the theory of the time evolution of P, and give graphical examples of the time evolution that contrast the behavior of stochastic learning with true gradient descent (batch learning). Finally, we use the formalism to obtain predictions of the time required for noise-induced hopping between basins of different optima. We compare the theoretical predictions with simulations of large ensembles of networks for simple problems in supervised and unsupervised learning.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1992/file/fae0b27c451c728867a567e8c1bb4e53-Paper.pdf",
  "title": "Transient Signal Detection with Neural Networks: The Search for the Desired Signal",
  "year": 1992,
  "venue": "NeurIPS",
  "abstract": "Matched filtering has been one of the most powerful techniques employed for transient detection. Here we will show that a dynamic neural network outperforms the conventional approach. When the artificial neural network (ANN) is trained with supervised learning schemes there is a need to supply the desired signal for all time, although we are only interested in detecting the transient. In this paper we also show the effects on the detection agreement of different strategies to construct the desired signal. The extension of the Bayes decision rule (011 desired signal), optimal in static classification, performs worse than desired signals constructed by random noise or prediction during the background.",
  "stance": -1.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1993/file/1efa39bcaec6f3900149160693694536-Paper.pdf",
  "title": "How to Describe Neuronal Activity: Spikes, Rates, or Assemblies?",
  "year": 1993,
  "venue": "NeurIPS",
  "abstract": "What is the 'correct' theoretical description of neuronal activity? The analysis of the dynamics of a globally connected network of spiking neurons (the Spike Response Model) shows that a description by mean firing rates is possible only if active neurons fire incoherently. If firing occurs coherently or with spatio-temporal correlations, the spike structure of the neural code becomes relevant. Alternatively, neurons can be gathered into local or distributed ensembles or 'assemblies'. A description based on the mean ensemble activity is, in principle, possible but the interaction between different assemblies becomes highly nonlinear. A description with spikes should therefore be preferred.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1993/file/22ac3c5a5bf0b520d281c122d1490650-Paper.pdf",
  "title": "Emergence of Global Structure from Local Associations",
  "year": 1993,
  "venue": "NeurIPS",
  "abstract": "A variant of the encoder architecture, where units at the input and output layers represent nodes on a graph. is applied to the task of mapping locations to sets of neighboring locations. The degree to which the resuIting internal (i.e. hidden unit) representations reflect global properties of the environment depends upon several parameters of the learning procedure. Architectural bottlenecks. noise. and incremental learning of landmarks are shown to be important factors in maintaining topographic relationships at a global scale.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1993/file/22fb0cee7e1f3bde58293de743871417-Paper.pdf",
  "title": "Robot Learning: Exploration and Continuous Domains",
  "year": 1993,
  "venue": "NeurIPS",
  "abstract": "The goal of this workshop was to discuss two major issues: efficient exploration of a learner's state space, and learning in continuous domains. The common themes that emerged in presentations and in discussion were the importance of choosing one's domain assumptions carefully, mixing controllers/strategies, avoidance of catastrophic failure, new approaches with difficulties with reinforcement learning, and the importance of task transfer.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1993/file/d4c2e4a3297fe25a71d030b67eb83bfc-Paper.pdf",
  "title": "Bayesian Backpropagation Over I-O Functions Rather Than Weights",
  "year": 1993,
  "venue": "NeurIPS",
  "abstract": "The conventional Bayesian justification of backprop is that it finds the MAP weight vector. As this paper shows, to find the MAP i-o function instead one must add a correction tenn to backprop. That tenn biases one towards i-o functions with small description lengths, and in particular favors (some kinds of) feature-selection, pruning, and weight-sharing.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1994/file/1e48c4420b7073bc11916c6c1de226bb-Paper.pdf",
  "title": "Interference in Learning Internal Models of Inverse Dynamics in Humans",
  "year": 1994,
  "venue": "NeurIPS",
  "abstract": "Experiments were performed to reveal some of the computational properties of the human motor memory system. We show that as humans practice reaching movements while interacting with a novel mechanical environment, they learn an internal model of the inverse dynamics of that environment. Subjects show recall of this model at testing sessions 24 hours after the initial practice. The representation of the internal model in memory is such that there is interference when there is an attempt to learn a new inverse dynamics map immediately after an anticorrelated mapping was learned. We suggest that this interference is an indication that the same computational elements used to encode the first inverse dynamics map are being used to learn the second mapping. We predict that this leads to a forgetting of the initially learned skill.",
  "stance": -0.5
 },
 {
  "url": "https://papers.neurips.cc/paper/1994/file/b56a18e0eacdf51aa2a5306b0f533204-Paper.pdf",
  "title": "A Study of Parallel Perturbative Gradient Descent",
  "year": 1994,
  "venue": "NeurIPS",
  "abstract": "We have continued our study of a parallel perturbative learning method [Alspector et al., 1993] and implications for its implementation in analog VLSI. Our new results indicate that, in most cases, a single parallel perturbation (per pattern presentation) of the function parameters (weights in a neural network) is theoretically the best course. This is not true, however, for certain problems and may not generally be true when faced with issues of implementation such as limited precision. In these cases, multiple parallel perturbations may be best as indicated in our previous results.",
  "stance": -1.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1994/file/e6cb2a3c14431b55aa50c06529eaa21b-Paper.pdf",
  "title": "Hyperparameters Evidence and Generalisation for an Unrealisable Rule",
  "year": 1994,
  "venue": "NeurIPS",
  "abstract": "Using a statistical mechanical formalism we calculate the evidence, generalisation error and consistency measure for a linear perceptron trained and tested on a set of examples generated by a non linear teacher. The teacher is said to be unrealisable because the student can never model it without error. Our model allows us to interpolate between the known case of a linear teacher, and an unrealisable, nonlinear teacher. A comparison of the hyperparameters which maximise the evidence with those that optimise the performance measures reveals that, in the non-linear case, the evidence procedure is a misleading guide to optimising performance. Finally, we explore the extent to which the evidence procedure is unreliable and find that, despite being sub-optimal, in some circumstances it might be a useful method for fixing the hyperparameters.",
  "stance": 0.3
 },
 {
  "url": "https://papers.neurips.cc/paper/1996/file/459a4ddcb586f24efd9395aa7662bc7c-Paper.pdf",
  "title": "Why did TD-Gammon Work?",
  "year": 1996,
  "venue": "NeurIPS",
  "abstract": "Although TD-Gammon is one of the major successes in machine learning, it has not led to similar impressive breakthroughs in temporal difference learning for other applications or even other games. We were able to replicate some of the success of TD-Gammon, developing a competitive evaluation function on a 4000 parameter feed-forward neural network, without using back-propagation, reinforcement or temporal difference learning methods. Instead we apply simple hill-climbing in a relative fitness environment. These results and further analysis suggest that the surprising success of Tesauro's program had more to do with the co-evolutionary structure of the learning task and the dynamics of the backgammon game itself.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1996/file/6c14da109e294d1e8155be8aa4b1ce8e-Paper.pdf",
  "title": "Promoting Poor Features to Supervisors: Some Inputs Work Better as Outputs",
  "year": 1996,
  "venue": "NeurIPS",
  "abstract": "In supervised learning there is usually a clear distinction between inputs and outputs inputs are what you will measure, outputs are what you will predict from those measurements. This paper shows that the distinction between inputs and outputs is not this simple. Some features are more useful as extra outputs than as inputs. By using a feature as an output we get more than just the case values but can. learn a mapping from the other inputs to that feature. For many features this mapping may be more useful than the feature value itself. We present two regression problems and one classification problem where performance improves if features that could have been used as inputs are used as extra outputs instead. This result is surprising since a feature used as an output is not used during testing.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1996/file/dc87c13749315c7217cdc4ac692e704c-Paper.pdf",
  "title": "Limitations of Self-organizing Maps for Vector Quantization and Multidimensional Scaling",
  "year": 1996,
  "venue": "NeurIPS",
  "abstract": "The limitations of using self-organizing maps (SaM) for either clustering/vector quantization (VQ) or multidimensional scaling (MDS) are being discussed by reviewing recent empirical findings and the relevant theory. SaM 's remaining ability of doing both VQ and MDS at the same time is challenged by a new combined technique of online K-means clustering plus Sammon mapping of the cluster centroids. SaM are shown to perform significantly worse in terms of quantization error , in recovering the structure of the clusters and in preserving the topology in a comprehensive empirical study using a series of multivariate normal clustering problems.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1996/file/f47330643ae134ca204bf6b2481fec47-Paper.pdf",
  "title": "Balancing Between Bagging and Bumping",
  "year": 1996,
  "venue": "NeurIPS",
  "abstract": "We compare different methods to combine predictions from neural networks trained on different bootstrap samples of a regression problem. One of these methods, introduced in [6] and which we here call balancing, is based on the analysis of the ensemble generalization error into an ambiguity term and a term incorporating generalization performances of individual networks. We show how to estimate these individual errors from the residuals on validation patterns. Weighting factors for the different networks follow from a quadratic programming problem. On a real-world problem concerning the prediction of sales figures and on the well-known Boston housing data set, balancing clearly outperforms other recently proposed alternatives as bagging [1] and bumping [8].",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1998/file/efb76cff97aaf057654ef2f38cd77d73-Paper.pdf",
  "title": "Utilizing lime: Asynchronous Binding",
  "year": 1998,
  "venue": "NeurIPS",
  "abstract": "Historically, connectionist systems have not excelled at representing and manipulating complex structures. How can a system composed of simple neuron-like computing elements encode complex relations? Recently, researchers have begun to appreciate that representations can extend in both time and space. Many researchers have proposed that the synchronous firing of units can encode complex representations. I identify the limitations of this approach and present an asynchronous model of binding that effectively represents complex structures. The asynchronous model extends the synchronous approach. I argue that our cognitive architecture utilizes a similar mechanism.",
  "stance": 0.2
 },
 {
  "url": "https://papers.neurips.cc/paper/1999/file/86d7c8a08b4aaa1bc7c599473f5dddda-Paper.pdf",
  "title": "Rules and Similarity in Concept Learning",
  "year": 1999,
  "venue": "NeurIPS",
  "abstract": "This paper argues that two apparently distinct modes of generalizing concepts abstracting rules and computing similarity to exemplars should both be seen as special cases of a more general Bayesian learning framework. Bayes explains the specific workings of these two modes which rules are abstracted, how similarity is measured as well as why generalization should appear ruleor similarity-based in different situations. This analysis also suggests why the rules/similarity distinction, even if not computationally fundamental, may still be useful at the algorithmic level as part of a principled approximation to fully Bayesian learning.",
  "stance": 0.0
 },
 {
  "url": "https://papers.neurips.cc/paper/1999/file/e9b73bccd1762555582b513ff9d02492-Paper.pdf",
  "title": "Acquisition in Autoshaping",
  "year": 1999,
  "venue": "NeurIPS",
  "abstract": "Quantitative data on the speed with which animals acquire behavioral responses during classical conditioning experiments should provide strong constraints on models of learning. However, most models have simply ignored these data; the few that have attempted to address them have failed by at least an order of magnitude. We discuss key data on the speed of acquisition, and show how to account for them using a statistically sound model of learning, in which differential reliabilities of stimuli playa crucial role.",
  "stance": 0.2
 }
]